[
  {
    "questionId": "q-sh-026",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "software-hardware",
    "topic": "プロセス間通信",
    "level": 6,
    "question": "複数のプロセスが大量のデータを高速に共有する必要がある場合、最も適したプロセス間通信（IPC）の方式はどれか。",
    "choices": [
      {
        "id": "a",
        "text": "パイプ（pipe）",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "パイプはデータを一方向にストリームとして流す仕組みであり、データのコピーがカーネルを経由するため、大量データの高速共有には向かない。また親子プロセス間など関係するプロセスが限られる。",
          "analogy": "パイプは水道管のようなもの。水（データ）を一方通行で流すことはできるが、大量の水を瞬時に別の場所で使いたい場合には向いていない。"
        }
      },
      {
        "id": "b",
        "text": "共有メモリ（shared memory）",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "共有メモリは複数のプロセスが同一のメモリ領域を直接参照・書き込みできる仕組みであり、カーネルを介したデータコピーが不要なため、IPCの中で最高の転送速度を実現できる。同期にはセマフォなどを組み合わせる必要がある。",
          "analogy": "共有メモリはオフィスの共有ホワイトボードのようなもの。複数の人（プロセス）が直接ホワイトボード（メモリ）を見て書き込めるので、いちいち紙に書いて渡す（データコピー）手間がなく最速でやりとりできる。",
          "deepDive": "共有メモリはshmget/shmat（POSIX: shm_open/mmap）などのシステムコールで確保し、プロセスが仮想アドレス空間に同じ物理ページをマッピングする。データコピーが発生しないのでスループットは最大だが、同時アクセスを排他制御（mutex/セマフォ）で管理しないとデータ競合（race condition）が起きる点に注意が必要。"
        }
      },
      {
        "id": "c",
        "text": "メッセージキュー（message queue）",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "メッセージキューはカーネルが管理するキューにメッセージを送受信する仕組みで、非同期通信に向くが、データはカーネル空間を経由してコピーされるため、大量データの高速共有には共有メモリより劣る。",
          "analogy": "メッセージキューは郵便ポストのようなもの。手紙（メッセージ）を投函して受け取る仕組みは便利だが、重い荷物（大量データ）を何度も郵便局（カーネル）経由で送るのは効率が悪い。"
        }
      },
      {
        "id": "d",
        "text": "ソケット（socket）",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "ソケットは主にネットワーク越しのプロセス間通信に用いられる。同一マシン上でも使えるが、プロトコルスタックを経由するオーバーヘッドがあり、大量データの高速共有には共有メモリが適している。",
          "analogy": "ソケットは電話回線のようなもの。遠くにいる人（別マシンのプロセス）と話すには便利だが、隣の席の人（同一マシンのプロセス）とやりとりするのにわざわざ電話を使うのは非効率。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "プロセス間通信（IPC）には、パイプ・共有メモリ・メッセージキュー・ソケットなど複数の方式がある。大量データを高速に共有したい場合は、カーネルを経由しないデータコピーが不要な共有メモリが最適。",
      "keyPoint": "共有メモリ＝最速のIPC。ただし同期制御（セマフォ/mutex）が必須。",
      "relatedTopics": ["セマフォ", "ミューテックス", "デッドロック", "プロセス管理"],
      "studyTip": "IPC方式を比較する問題では「速度」「方向性（単方向/双方向）」「スコープ（同一マシン/ネットワーク）」の3軸で整理すると選択肢を絞りやすい。"
    },
    "tags": ["IPC", "共有メモリ", "パイプ", "メッセージキュー", "プロセス間通信"]
  },
  {
    "questionId": "q-sh-027",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "software-hardware",
    "topic": "ワーキングセット",
    "level": 6,
    "question": "ワーキングセット（working set）の説明として、最も適切なものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "プロセスが使用する仮想アドレス空間の合計サイズ",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "仮想アドレス空間の合計サイズはプロセスの仮想メモリサイズであり、ワーキングセットとは異なる。ワーキングセットは「直近で実際にアクセスされたページの集合」を指す。",
          "analogy": "図書館（仮想アドレス空間）にある本すべての数ではなく、ある期間に実際に読んだ本の集まりがワーキングセット。"
        }
      },
      {
        "id": "b",
        "text": "プロセスが直近の時間窓内に参照したページの集合",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "ワーキングセットとは、プロセスが直近の一定時間（時間窓）内に参照したページの集合のことである。OSはこの集合をメインメモリ上に保持することでページフォルトを抑制し、スラッシングを防ぐ。",
          "analogy": "仕事机（メインメモリ）に置いておく書類は、「直近の仕事で使った書類（ワーキングセット）」だけに絞ると効率的。不要な書類は棚（ディスク）に戻せばよい。",
          "deepDive": "ワーキングセットモデルはDenningが提唱した概念で、時間窓Δの中でアクセスされたページ集合W(t,Δ)をワーキングセットと定義する。OSはプロセスのワーキングセットが全てメモリ上にある状態を維持しようとする。ワーキングセットよりも割り当てられたフレーム数が少ないとスラッシングが発生する。"
        }
      },
      {
        "id": "c",
        "text": "CPUが一度のサイクルで処理できる命令セットの集合",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "命令セットはISA（Instruction Set Architecture）の概念であり、ワーキングセットとは全く無関係。ワーキングセットはメモリ管理における概念である。",
          "analogy": "料理人が使える包丁の種類（命令セット）と、今日の仕込みで実際に使った調理器具一式（ワーキングセット）は別の話。"
        }
      },
      {
        "id": "d",
        "text": "ディスク上のスワップ領域のうち、現在使用中の領域",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "スワップ領域の使用状況とワーキングセットは異なる概念。ワーキングセットはメインメモリ上の「最近参照されたページ集合」であり、ディスク上の概念ではない。",
          "analogy": "倉庫（スワップ領域）にある荷物のうち今使っているものではなく、作業場（メインメモリ）で最近実際に手を触れた道具がワーキングセット。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "ワーキングセットとは、プロセスが直近の時間窓内に参照したページの集合。OSがこれをメモリ上に保持することでページフォルトを最小化し、スラッシングを防ぐ。",
      "keyPoint": "ワーキングセット＝「直近Δ時間内に参照したページの集合」。スラッシング対策の基本概念。",
      "relatedTopics": ["スラッシング", "ページ置換アルゴリズム", "仮想記憶", "ページフォルト"],
      "studyTip": "ワーキングセットは「時間窓」という概念がキーワード。過去問では「スラッシングの原因・対策」とセットで出題されることが多いので関連付けて覚えよう。"
    },
    "tags": ["ワーキングセット", "仮想記憶", "ページング", "スラッシング", "メモリ管理"]
  },
  {
    "questionId": "q-sh-028",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "software-hardware",
    "topic": "ディスク容量計算",
    "level": 6,
    "question": "セクタサイズが512バイト、1トラックあたりのセクタ数が63、1シリンダあたりのトラック数が255（ヘッド数255）、シリンダ数が16383のハードディスクがある。このディスクの総容量として最も近い値はどれか。",
    "choices": [
      {
        "id": "a",
        "text": "約80GB",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "計算式：512 × 63 × 255 × 16383 ≒ 128.5GBであり、80GBは大幅に小さい誤った値。計算の桁を誤った場合にこの値になりやすい。",
          "analogy": "棚の本の数を数えるとき、棚の段数を間違えると総数が大きくずれるのと同じ誤り。"
        }
      },
      {
        "id": "b",
        "text": "約128GB",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "総容量 ＝ セクタサイズ × セクタ/トラック × トラック/シリンダ × シリンダ数 ＝ 512 × 63 × 255 × 16383 ≒ 128,849,018,880バイト ≒ 128.5GB。これはLBAアドレッシング以前のCHSアドレッシングの限界値（約137GB, 128 GiB）として知られる値に相当する。",
          "analogy": "棚（シリンダ）が16383個あり、各棚に255段（トラック）、各段に63冊（セクタ）、各冊が512ページ（バイト）あると考えれば、全ページ数（総容量）が計算できる。",
          "deepDive": "この数値（63セクタ/トラック、255ヘッド、16383シリンダ）はBIOSのCHSアドレッシング限界値として歴史的に重要。実際の計算：512 × 63 × 255 × 16383 = 128,849,018,880バイト ≒ 120.0 GiB（1GiB=2^30バイト）≒ 128.8 GB（1GB=10^9バイト）。現代のディスクはLBA（論理ブロックアドレッシング）でこの制限を超えている。"
        }
      },
      {
        "id": "c",
        "text": "約256GB",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "256GBは正しい計算結果の約2倍。セクタサイズを1024バイトと誤って計算した場合などにこの値になる。正しいセクタサイズは512バイト。",
          "analogy": "本の厚さ（バイト数）を2倍に数え間違えると本棚全体の容量も2倍になる誤り。"
        }
      },
      {
        "id": "d",
        "text": "約512GB",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "512GBは正しい計算結果の約4倍。セクタ数や別のパラメータを誤って大きく計算した場合の誤り。",
          "analogy": "本棚の段数を4倍に読み間違えると総ページ数も4倍になってしまう誤り。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "ディスク容量の計算式は「セクタサイズ × セクタ数/トラック × トラック数/シリンダ × シリンダ数」。CHSアドレッシングの限界値（16383/255/63）は歴史的に重要な数値。",
      "keyPoint": "容量 ＝ セクタサイズ × (セクタ/トラック) × (トラック/シリンダ) × シリンダ数。単位変換（GB/GiB）に注意。",
      "relatedTopics": ["CHS（シリンダ・ヘッド・セクタ）", "LBA", "ストレージアーキテクチャ", "ディスク構造"],
      "studyTip": "ディスク容量計算は掛け算の組み合わせ。「1セクタ何バイト？トラックに何セクタ？シリンダに何トラック？シリンダいくつ？」と順番に確認する習慣をつけよう。"
    },
    "tags": ["ディスク容量", "CHS", "セクタ", "トラック", "シリンダ", "ストレージ計算"]
  },
  {
    "questionId": "q-sh-029",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "software-hardware",
    "topic": "フォーマット",
    "level": 6,
    "question": "論理フォーマットと物理フォーマットに関する記述として、適切なものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "物理フォーマットはOSがファイルシステムを書き込む処理であり、論理フォーマットはディスクのセクタを初期化する処理である。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "説明が逆になっている。物理フォーマット（ローレベルフォーマット）はセクタなどの物理的構造を初期化する処理であり、論理フォーマットはファイルシステムを書き込む処理である。",
          "analogy": "土地の造成工事（物理フォーマット）と間取り設計・内装工事（論理フォーマット）を逆に説明している誤り。"
        }
      },
      {
        "id": "b",
        "text": "論理フォーマットはファイルシステムの構造（FAT、MFTなど）をディスクに書き込む処理であり、物理フォーマットはセクタ境界や同期信号などを磁気ディスク上に記録する処理である。",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "論理フォーマット（高レベルフォーマット）はFATやNTFSのMFTなどのファイルシステム構造を書き込む処理。物理フォーマット（ローレベルフォーマット）はセクタ境界・同期信号・ECC領域などをディスク媒体に書き込む処理。両者は目的・タイミング・対象が異なる。",
          "analogy": "物理フォーマットは土地を整地して区画（セクタ）を決める造成工事。論理フォーマットはその土地に間取り（ファイルシステム）を作る内装工事。まず造成（物理）してから間取り（論理）を決める順番が正しい。",
          "deepDive": "現代のHDDは出荷時に物理フォーマット済みのため、ユーザーが物理フォーマットを行う機会はほとんどない。ユーザーが行う「フォーマット」は論理フォーマットを指すことが多い。SSDでは物理的なセクタという概念がなくNANDフラッシュ管理はFTL（フラッシュ変換レイヤ）が担う。"
        }
      },
      {
        "id": "c",
        "text": "論理フォーマットを行うと、ディスクの物理的な不良セクタが修復される。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "論理フォーマットは不良セクタの修復は行わない。不良セクタの検出と代替セクタへの割り当てはスキャンディスクやS.M.A.R.T.機能、または物理フォーマット時に行われる。",
          "analogy": "部屋の模様替え（論理フォーマット）をしても、壁のひび割れ（不良セクタ）は直らない。ひび割れを直すには建設工事（物理フォーマット・修復ツール）が必要。"
        }
      },
      {
        "id": "d",
        "text": "物理フォーマットはOSを問わず共通の処理であるが、論理フォーマットも特定のOSに依存せず汎用的な処理である。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "物理フォーマットはディスクのハードウェア仕様に依存し共通性が高いが、論理フォーマットはFAT32・NTFS・ext4・APFSなどOS依存のファイルシステムに固有であり、汎用的ではない。",
          "analogy": "土地の造成工事（物理フォーマット）は業者が共通の方法で行えるが、内装デザイン（論理フォーマット）は住む人（OS）によってまったく異なる。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "物理フォーマットはディスクの物理的な構造（セクタ境界・同期信号）を書き込む処理。論理フォーマットはファイルシステム（FAT・NTFS・ext4など）の構造を書き込む処理。両者は目的と対象が異なる。",
      "keyPoint": "物理＝ハードウェアレベルの初期化（セクタ構造）。論理＝OSレベルの初期化（ファイルシステム構造）。",
      "relatedTopics": ["ファイルシステム", "FAT", "NTFS", "ext4", "不良セクタ"],
      "studyTip": "「物理→論理」の順序（まずディスクの構造を作ってからファイルシステムを載せる）を意識すると混乱しにくい。"
    },
    "tags": ["フォーマット", "物理フォーマット", "論理フォーマット", "ファイルシステム", "ディスク"]
  },
  {
    "questionId": "q-sh-030",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "software-hardware",
    "topic": "ファームウェア",
    "level": 6,
    "question": "ファームウェア（firmware）の更新（アップデート）に関する記述として、最も適切なものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "ファームウェアの更新はOSのカーネルが管理するため、OSのアップデートと同時に自動的に行われる。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "ファームウェアはOSとは独立したソフトウェアであり、OSのカーネルが管理するものではない。BIOS/UEFIのファームウェア更新はOSとは別の手順で行う必要がある。",
          "analogy": "テレビのリモコン（ファームウェア）のバッテリー交換は、テレビ本体（OS）の修理とは別の作業。一緒に自動でやってくれるわけではない。"
        }
      },
      {
        "id": "b",
        "text": "ファームウェアはハードウェアに組み込まれたソフトウェアであり、更新に失敗すると機器が起動不能になるリスクがある。",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "ファームウェアはROM・フラッシュメモリなどにハードウェアと密接に組み込まれたソフトウェア（BIOS/UEFI・ルータのFW・SSDのコントローラFWなど）。更新中に電源断や書き込み失敗が起きると、起動プログラム自体が破損して機器が文鎮化（brick）するリスクがある。",
          "analogy": "ファームウェアは機械の設計図のようなもの。設計図の書き換え中に電気が切れると、機械がどう動けばいいか分からなくなって動かなくなる（文鎮化）。",
          "deepDive": "この問題を回避するためにデュアルバンク方式（現行FWと新FWを別領域に保持して切り替える）が採用される機器もある。例えばUEFIの一部実装では、更新失敗時にバックアップから復元する機能を持つ。ファームウェア更新中は必ず電源を維持し、操作を中断しないことが重要。"
        }
      },
      {
        "id": "c",
        "text": "ファームウェアはRAMに格納されているため、機器の電源を切ると更新内容が消える。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "ファームウェアはRAMではなくROMやNANDフラッシュなどの不揮発性メモリに格納されているため、電源を切っても内容は保持される。RAMに格納されていればそもそも電源投入時に読み込むことができない。",
          "analogy": "ファームウェアは本（不揮発性メモリ）に書かれているので電気が切れても消えない。メモ用紙（RAM）に書いたものとは違う。"
        }
      },
      {
        "id": "d",
        "text": "ファームウェアの更新はネットワークを通じて行うことはできず、必ず専用の書き込み装置が必要である。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "現代のファームウェアはOTA（Over The Air）やネットワーク越しのアップデートに対応しているものが多い（ルータ・スマートフォン・IoT機器など）。専用書き込み装置が必要な場面は限定的である。",
          "analogy": "昔は書き換えに特殊な機械が必要だったが、今のスマートフォンのソフト更新はネットワーク越しに手軽にできる。それと同じ進化がファームウェアにも起きている。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "ファームウェアはハードウェアに組み込まれた不揮発性メモリ上のソフトウェア。更新失敗による機器の起動不能（文鎮化）リスクがあるため、更新中の電源断には特に注意が必要。",
      "keyPoint": "ファームウェア更新の最大リスク＝更新失敗による文鎮化（brick）。不揮発性メモリに書き込むので電源断は致命的。",
      "relatedTopics": ["BIOS", "UEFI", "フラッシュメモリ", "ROM", "OTAアップデート"],
      "studyTip": "「ファームウェア＝ハードウェアとOSの橋渡しをする組み込みソフト」と覚えよう。OSとは独立して管理・更新される点がポイント。"
    },
    "tags": ["ファームウェア", "BIOS", "UEFI", "フラッシュメモリ", "文鎮化", "OTA"]
  },
  {
    "questionId": "q-sh-031",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "software-hardware",
    "topic": "OSカーネルアーキテクチャ",
    "level": 7,
    "question": "マイクロカーネル（microkernel）とモノリシックカーネル（monolithic kernel）を比較した説明として、適切なものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "マイクロカーネルはモノリシックカーネルと比べて、一般にカーネル空間で動作するコードの量が多く、高い性能を発揮する。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "マイクロカーネルはカーネル空間のコードを最小限に絞り、多くの機能をユーザー空間に移動させる設計であるため、カーネル空間のコード量はモノリシックより少ない。性能ではモノリシックのほうが一般に高い。",
          "analogy": "マイクロカーネルは少数精鋭のコア部隊（カーネル空間が小さい）で、実務はスタッフ（ユーザー空間）に任せる組織。逆の説明になっている。"
        }
      },
      {
        "id": "b",
        "text": "モノリシックカーネルはデバイスドライバやファイルシステムもカーネル空間で動作するため、コンポーネント間の通信オーバーヘッドが小さく性能が高い傾向にある。",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "モノリシックカーネルはデバイスドライバ・ファイルシステム・スケジューラなどをすべてカーネル空間にまとめて動作させる。コンポーネント間はメモリ内での直接関数呼び出しで通信するため、コンテキストスイッチやIPCのオーバーヘッドが少なく高性能。一方でカーネルが大きくなりバグがシステム全体に影響しやすい。",
          "analogy": "モノリシックカーネルはすべての部署が同じ大きなオフィスフロア（カーネル空間）で働くビル。隣の席に話しかけるだけで済む（低オーバーヘッド）が、誰かがミスをすると全フロアに影響が出る（バグの影響が大きい）。",
          "deepDive": "Linuxはモノリシックカーネルの代表例だが、ローダブルカーネルモジュール（LKM）によって動的にドライバを追加できる「モジュラー型モノリシックカーネル」とも言える。マイクロカーネルの代表例にはMinix・GNU Hurd・macOS/iOSのXNU（ハイブリッド型）がある。マイクロカーネルは安全性・保守性が高いがIPCのオーバーヘッドが性能のボトルネックになりやすい。"
        }
      },
      {
        "id": "c",
        "text": "マイクロカーネルはデバイスドライバのバグがカーネル全体をクラッシュさせやすく、信頼性が低い。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "これはモノリシックカーネルの特性の説明。マイクロカーネルはデバイスドライバをユーザー空間で動作させるため、ドライバのバグがカーネル全体に波及しにくく信頼性が高い。",
          "analogy": "マイクロカーネルは各部署が別々のビル（ユーザー空間）で働く組織。ある部署（ドライバ）が火事になっても、本社（カーネル）は別のビルにあるので燃え広がらない。"
        }
      },
      {
        "id": "d",
        "text": "モノリシックカーネルはカーネルのコードサイズが非常に小さく、組み込みシステムに特に適している。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "モノリシックカーネルはすべての機能をカーネル空間に持つため、コードサイズは大きくなる傾向がある。コンパクトさが求められる組み込みシステムにはマイクロカーネルやRTOSが採用されることが多い。",
          "analogy": "モノリシックカーネルは大型スーパー（機能が全部入り）なので、狭い商店街（組み込みシステム）には向かない。小さくて機能を絞った個人商店（マイクロカーネル）のほうが向いている。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "モノリシックカーネルは全機能をカーネル空間に集約し性能が高い一方でバグの影響範囲が大きい。マイクロカーネルは最小限の機能のみカーネル空間に置き、ドライバ等をユーザー空間で動かすため信頼性・保守性が高いがIPCオーバーヘッドによる性能低下が課題。",
      "keyPoint": "モノリシック＝高性能・低信頼性（バグ影響大）。マイクロ＝高信頼性・低性能（IPC開銷）。",
      "relatedTopics": ["カーネル", "デバイスドライバ", "ユーザー空間", "カーネル空間", "RTOS"],
      "studyTip": "「モノリシック＝1枚岩」「マイクロ＝小さいコア」というネーミングから特徴が連想できる。LinuxがモノリシックでMinixがマイクロカーネルという具体例と一緒に覚えよう。"
    },
    "tags": ["マイクロカーネル", "モノリシックカーネル", "OS設計", "カーネル空間", "ユーザー空間"]
  },
  {
    "questionId": "q-sh-032",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "software-hardware",
    "topic": "スラッシング",
    "level": 7,
    "question": "仮想記憶システムでスラッシング（thrashing）が発生している状態の説明として、最も適切なものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "CPUの処理速度に比べてメモリのアクセス速度が遅いため、CPUがメモリ待ちになる現象である。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "これはCPUとメモリ間の速度差によるウェイト（待機状態）の説明であり、スラッシングとは異なる。スラッシングはページフォルトが頻発してCPUがほとんどページ入れ替えに消費される状態。",
          "analogy": "これはCPUが仕事を待つ「待ち状態」の話。スラッシングはCPUが「本来の仕事ではなく引っ越し作業ばかりしている」という話で別の問題。"
        }
      },
      {
        "id": "b",
        "text": "プロセスに割り当てられた物理メモリフレームが不足し、ページフォルトが頻発してページ入れ替えにCPU時間の大半が費やされる状態である。",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "スラッシングとは、プロセスのワーキングセットを保持するのに必要な物理メモリフレームが不足しているとき、ページフォルトが連続して発生し、CPUがページのスワップイン・スワップアウトに大半の時間を費やし、本来の処理がほとんど進まなくなる状態のことである。",
          "analogy": "机（物理メモリ）が狭すぎて、仕事をするたびに書類（ページ）を棚（ディスク）から出し入れすることになり、本来の仕事（プロセスの処理）がほとんど進まなくなる状態がスラッシング。",
          "deepDive": "スラッシングが発生するとCPU利用率は逆説的に低下する（CPUがディスクI/O待ちになるため）。対策としては、（1）プロセス数を減らして1プロセスあたりのメモリを増やす、（2）物理メモリを増設する、（3）ワーキングセットモデルに基づいてページ割り当てを制御する、などがある。"
        }
      },
      {
        "id": "c",
        "text": "ディスクのスピンドルが過熱し、読み書き速度が低下する物理的な現象である。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "スラッシングはソフトウェア（OS・仮想記憶管理）レベルの現象であり、ディスクの物理的な過熱とは無関係。",
          "analogy": "スラッシングは机と棚の往復疲れ（ページ入れ替えの多さ）であって、棚が熱くなる（ディスク過熱）とは別の話。"
        }
      },
      {
        "id": "d",
        "text": "複数のプロセスが同一のロックを取得しようとして、互いに待ち続けるデッドロック状態のことである。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "デッドロックとスラッシングは異なる概念。デッドロックは複数プロセスが互いに相手のリソース解放を待ち続ける状態。スラッシングはページフォルトの頻発によるI/O過多の状態。",
          "analogy": "デッドロックは「あなたが先にどいてくれたら私もどく」と言い合って永遠に動けない渋滞。スラッシングは「書類を棚から出す・戻すを繰り返していて仕事が進まない」状態。別の問題。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "スラッシングとは、物理メモリ不足でページフォルトが頻発し、CPUのほとんどの時間がページのスワップイン・アウトに消費されて本来の処理が進まなくなる状態。逆説的にCPU利用率が低下する点も重要。",
      "keyPoint": "スラッシング＝メモリ不足→ページフォルト多発→スワップ多発→CPU利用率が逆に低下する悪循環。",
      "relatedTopics": ["ワーキングセット", "ページフォルト", "仮想記憶", "スワップ", "物理メモリ"],
      "studyTip": "「スラッシング」は英語で「激しく叩く・もがく」の意味。CPUがページ入れ替えで必死にもがいてもなかなか前に進めない様子をイメージすると覚えやすい。"
    },
    "tags": ["スラッシング", "仮想記憶", "ページフォルト", "スワップ", "メモリ管理"]
  },
  {
    "questionId": "q-sh-033",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "software-hardware",
    "topic": "ディスクフラグメンテーション",
    "level": 7,
    "question": "ハードディスクのフラグメンテーション（断片化）に関する記述として、最も適切なものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "フラグメンテーションはSSDでも頻繁に発生し、HDD向けのデフラグツールをSSDに実行することでパフォーマンスが改善される。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "SSDはランダムアクセスがHDDと異なりほぼ一定速度であるため、フラグメンテーションによる性能低下はほとんどない。さらにSSDに不必要なデフラグを実行すると書き込み回数が増えてSSDの寿命を縮める恐れがある。",
          "analogy": "HDD（回転する机）では書類がバラバラだと探す時間が増えるが、SSD（全部が手元の棚）ではどこに書類があっても取り出す時間は同じ。むしろ頻繁に整理（デフラグ）しすぎると棚が傷む。"
        }
      },
      {
        "id": "b",
        "text": "フラグメンテーションとは、ファイルの削除・追加を繰り返すことでHDD上のファイルデータが不連続な場所に断片化して格納された状態であり、読み書き速度が低下する原因となる。",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "ファイルを何度も作成・削除すると、ディスク上に空き領域が断片化し、新しいファイルが不連続な複数のクラスタに分散して格納されるフラグメンテーションが発生する。HDDの読み書きヘッドが離れた場所に移動するシーク回数が増えるため読み書き速度が低下する。デフラグメンテーションツールでファイルを連続領域に再配置することで改善できる。",
          "analogy": "本棚（ディスク）に本（ファイル）を出し入れしていると、1冊の本が棚の複数の場所にバラバラに置かれる状態になる。読もうとするたびにあちこち移動（シーク）する必要があり効率が悪い。これがフラグメンテーション。",
          "deepDive": "ファイルシステムによってフラグメンテーションの発生しやすさは異なる。NTFS（Windows）は事前にある程度の連続領域を確保しようとする。ext4（Linux）はグループ機能でフラグメンテーションを抑制する。デフラグの仕組みはファイルを一時的にコピーし、連続した領域に再書き込みする処理。"
        }
      },
      {
        "id": "c",
        "text": "フラグメンテーションが発生しても、OSが自動的にリアルタイムでデフラグを行うため、ユーザーが意識する必要はない。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "OSによってはバックグラウンドでデフラグを自動実行する機能を持つ（Windows Vista以降など）が、リアルタイムで完全にフラグメンテーションを防ぐわけではなく、ユーザーが手動でデフラグを実行すべき場面もある。また「意識する必要はない」というのは過大な表現。",
          "analogy": "掃除ロボット（自動デフラグ）がある程度片付けてくれるが、大掃除（手動デフラグ）が必要な状況もある。「完全に任せて大丈夫」は言い過ぎ。"
        }
      },
      {
        "id": "d",
        "text": "フラグメンテーションはRAM上でのみ発生する問題であり、電源を切るとリセットされる。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "フラグメンテーションはHDD・SSDなどの永続ストレージ上で発生する問題であり、電源断でリセットされない。RAMは揮発性であり、そもそもファイルシステムとは異なる概念なのでRAM上のフラグメンテーションという話にはならない。",
          "analogy": "フラグメンテーションはノート（HDD）にページがバラバラに書かれた状態。ノートは電気が切れても内容が消えない。消えるのはホワイトボード（RAM）の内容。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "フラグメンテーションはHDD上でファイルが不連続に断片化した状態で、シーク回数増加により読み書き速度が低下する。デフラグツールで解消できる。SSDへのデフラグは逆効果になるため注意。",
      "keyPoint": "HDD：フラグメンテーション→シーク増加→速度低下。SSD：フラグメンテーションの影響小、デフラグで寿命が縮まるリスクあり。",
      "relatedTopics": ["デフラグメンテーション", "ファイルシステム", "クラスタ", "SSD", "HDD"],
      "studyTip": "「HDDにはデフラグが有効、SSDには不要・有害」というセットで覚えると実践的。試験ではHDDとSSDの違いを問う問題が増えている。"
    },
    "tags": ["フラグメンテーション", "デフラグ", "HDD", "SSD", "ファイルシステム", "クラスタ"]
  },
  {
    "questionId": "q-sh-034",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "software-hardware",
    "topic": "RAID",
    "level": 7,
    "question": "RAID 5と RAID 6の性能・信頼性の比較として、適切なものはどれか。なお、ディスク1台の容量をC、ドライブ数をnとする。",
    "choices": [
      {
        "id": "a",
        "text": "RAID 5は2台のディスク故障に耐えられるが、RAID 6は1台の故障にしか耐えられない。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "説明が逆。RAID 5は1台の故障まで耐えられ、RAID 6は2台同時故障まで耐えられる。RAID 6はパリティを2重化しているため冗長性が高い。",
          "analogy": "RAID 5は保険が1枚（1台故障OK）、RAID 6は保険が2枚（2台故障OK）。多い方が安全という説明が逆になっている。"
        }
      },
      {
        "id": "b",
        "text": "RAID 6はRAID 5よりも書き込み性能が低下しやすいが、2台同時のディスク故障にも耐えられる信頼性を持つ。",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "RAID 5は分散パリティ1つを計算して書き込む。RAID 6はP・Qの2種類のパリティを計算するため、書き込み時の計算オーバーヘッドが増え書き込み性能がRAID 5よりも低い傾向にある。一方で2台のドライブが同時に故障しても、残りのドライブとパリティから全データを復元できる高い信頼性を持つ。",
          "analogy": "RAID 5は安全ネットが1枚（1台故障OK）。RAID 6は2枚の安全ネット（2台同時故障OK）を張るため、ネットを張る作業（書き込み計算）が増えて少し遅くなるが、1枚破れてももう1枚で支えられる。",
          "deepDive": "RAID 6の使用可能容量は(n-2)×C（パリティ2台分が冗長）。書き込み時はQ-パリティにガロア体演算（GF(2^8)）を使うため計算コストが高い。大容量ディスク時代ではRAID 5再構築中に第2のディスク故障が起きる「URE（Unrecoverable Read Error）」リスクが高まるため、RAID 6やRAID 6ベースのRAID-Zが推奨される。"
        }
      },
      {
        "id": "c",
        "text": "RAID 5とRAID 6は同一台数のディスクに対して同じ使用可能容量を持つ。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "RAID 5の使用可能容量は(n-1)×C、RAID 6は(n-2)×C。RAID 6はパリティを2台分持つため、同一台数でも使用可能容量がRAID 5より少ない。",
          "analogy": "RAID 5は棚1段を予備（パリティ）に使い、RAID 6は2段を予備に使う。同じ棚の数なら予備が多いほど使える棚が減る。"
        }
      },
      {
        "id": "d",
        "text": "RAID 5はストライピングのみを使用し、パリティ情報を持たないため最も読み込み速度が速い。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "ストライピングのみでパリティを持たないのはRAID 0。RAID 5は分散パリティを持つ構成。RAID 0の説明をRAID 5に当てはめた誤り。",
          "analogy": "パリティなしの全力疾走（RAID 0）とパリティありの安全走行（RAID 5）を混同した説明。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "RAID 5は1台故障まで許容し、パリティ1重で書き込みオーバーヘッドが小さい。RAID 6は2台同時故障まで許容する高信頼性だが、パリティ2重計算により書き込み性能がやや低下し、使用可能容量も少ない。",
      "keyPoint": "RAID 5：1台障害耐性。RAID 6：2台障害耐性、書き込みコスト増。大容量時代はRAID 6が主流。",
      "relatedTopics": ["RAID 0", "RAID 1", "RAID 5", "RAID 6", "パリティ", "ストライピング"],
      "studyTip": "RAIDの番号と特徴を表でまとめると整理しやすい。RAID 5/6の違いは「パリティの枚数（1枚vs2枚）」と「耐故障数（1台vs2台）」で覚えよう。"
    },
    "tags": ["RAID", "RAID5", "RAID6", "パリティ", "ストライピング", "冗長化", "ストレージ"]
  },
  {
    "questionId": "q-sh-035",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "software-hardware",
    "topic": "エミュレータとシミュレータ",
    "level": 7,
    "question": "エミュレータ（emulator）とシミュレータ（simulator）の違いとして、最も適切な説明はどれか。",
    "choices": [
      {
        "id": "a",
        "text": "エミュレータは実際のハードウェアと同一の動作環境を提供するが、シミュレータはモデルに基づいて挙動を模倣するだけで、実際の動作環境とは異なる場合がある。",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "エミュレータは対象ハードウェアの動作を完全に再現し、そのハードウェア向けのソフトウェア（バイナリ）をそのまま実行できる（例：ゲーム機エミュレータ、JVM、Wine）。シミュレータは対象システムの挙動をモデルで近似的に再現するが、実際のバイナリを直接実行するとは限らない（例：CPU設計検証シミュレータ、飛行機シミュレータ、市場シミュレーション）。",
          "analogy": "エミュレータは「別のゲーム機（ハード）をパソコンに完全に再現してゲームをそのまま動かすもの」。シミュレータは「飛行機の操縦を練習するための模擬装置」で実際の飛行機とは異なるが挙動を模倣する。",
          "deepDive": "コンピュータの世界では、エミュレータはターゲットのISA（命令セットアーキテクチャ）を解釈・実行するので、ターゲット向けバイナリが変更不要で動く。代表例：QEMU（x86をARM上で動かすなど）、レトロゲーム機エミュレータ。シミュレータは設計・検証目的が多い。例：RTL（Register Transfer Level）シミュレータ、ネットワークシミュレータ（ns-3など）。"
        }
      },
      {
        "id": "b",
        "text": "シミュレータはハードウェアを完全に置き換えてバイナリを実行できるが、エミュレータはあくまで近似的な動作しかできない。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "説明が逆。バイナリを完全に実行できるのはエミュレータ、近似的な動作モデルを提供するのはシミュレータ。",
          "analogy": "「本物の食材で料理（エミュレータ）」と「料理の栄養を計算するソフト（シミュレータ）」の説明が入れ替わっている。"
        }
      },
      {
        "id": "c",
        "text": "エミュレータとシミュレータは同義であり、どちらも対象システムを完全に再現する。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "エミュレータとシミュレータは異なる概念。エミュレータは完全な動作再現、シミュレータは挙動の近似モデル提供であり、目的・精度・適用場面が異なる。",
          "analogy": "本物のゲーム機を完全に再現するエミュレータと、ゲームの動作を解析するシミュレータは似て非なるもの。"
        }
      },
      {
        "id": "d",
        "text": "エミュレータはソフトウェアのみで実装されるが、シミュレータはハードウェアを含む物理装置である。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "エミュレータはソフトウェアで実装されるものが多いが、ハードウェアエミュレータも存在する（FPGAを使ったロジックエミュレータなど）。シミュレータも多くがソフトウェアで実装される。実装手段の違いではなく「完全再現か近似モデルか」が本質的な違い。",
          "analogy": "エミュレータが全部デジタルで、シミュレータが全部物理だというわけではなく、どちらもソフト・ハード両方で実現される。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "エミュレータはターゲットハードウェアの動作を完全に再現し、対象向けバイナリをそのまま実行できる。シミュレータは対象の挙動をモデルに基づいて近似的に再現し、検証・分析・教育目的で使われることが多い。",
      "keyPoint": "エミュレータ＝完全再現（バイナリ実行可能）。シミュレータ＝近似モデル（挙動を模倣）。",
      "relatedTopics": ["仮想マシン", "QEMU", "コンテナ", "バーチャルマシン", "FPGA"],
      "studyTip": "「emulate＝完全に模倣する」「simulate＝シミュレート（近似）する」という英単語の意味をそのまま適用すると区別しやすい。"
    },
    "tags": ["エミュレータ", "シミュレータ", "仮想化", "QEMU", "ハードウェア再現"]
  },
  {
    "questionId": "q-sh-036",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "software-hardware",
    "topic": "割り込み優先制御",
    "level": 8,
    "question": "OSの割り込み優先制御に関する説明として、適切なものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "優先度の低い割り込みが処理中であっても、優先度の高い割り込みは必ず待たされる。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "優先度の高い割り込みが発生した場合、低優先度の割り込み処理を中断（プリエンプション）し、高優先度の割り込みハンドラを先に実行するのが割り込み優先制御の目的。低優先度の処理が完了するまで高優先度割り込みが待つのは優先制御を実施していない場合の動作。",
          "analogy": "救急車（高優先度割り込み）が来たら、普通の車（低優先度割り込み）は道を譲らなければいけない。救急車を普通の車の後ろで待たせるのは優先制御ではない。"
        }
      },
      {
        "id": "b",
        "text": "割り込みが多重に発生した場合、優先度の高い割り込みハンドラが実行中に更に高優先度の割り込みが発生すると、実行中のハンドラを中断して新たな割り込みを処理する多重割り込みが発生し得る。",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "多くのOSは多重割り込みをサポートしており、より高優先度の割り込みが発生した場合、実行中の割り込みハンドラを中断（プリエンプション）して高優先度の割り込みハンドラを実行する。完了後に中断されたハンドラに戻る。これにより、リアルタイム性を必要とする割り込み（タイマー・緊急デバイスなど）を遅延なく処理できる。",
          "analogy": "EM（緊急係）が仕事中に消防（超緊急割り込み）から呼ばれたら仕事を中断して消防に対応し、戻ってきて仕事を続ける。この多重対応（多重割り込み）が高優先度処理の迅速な実行を保証する。",
          "deepDive": "多重割り込みを許可するかどうかはCPUのフラグ（x86のIFフラグ）や割り込みコントローラ（PIC/APIC）の設定で制御される。割り込みハンドラの先頭でCLI（割り込み無効化）を実行すると多重割り込みを禁止できる。リアルタイムOS（RTOS）では優先度ごとに精密な割り込み制御が必要。Linuxでは割り込みハンドラを「ハードウェア割り込みハンドラ（上半分）」と「ソフト割り込み/タスクレット（下半分）」に分離して多重割り込みを管理する。"
        }
      },
      {
        "id": "c",
        "text": "すべての割り込みは同一の優先度で処理され、先着順（FIFO）で処理される。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "割り込みには優先度が設定されており、高優先度割り込みが優先的に処理される。タイマー割り込み・電源異常割り込みなどは最高優先度で扱われ、低優先度の処理より先に実行される。すべてを同一優先度として扱うのは多くのOS・ハードウェアの実態とは異なる。",
          "analogy": "病院の救急外来では、患者の到着順ではなく症状の重さ（優先度）で診察順が決まる。先着順ではない。"
        }
      },
      {
        "id": "d",
        "text": "割り込み処理中はOSがすべての割り込みを永久に無効化するため、複数の割り込みが同時に発生することはない。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "割り込みハンドラ実行中に一時的に割り込みを無効化する実装もあるが、「永久に無効化する」のは誤り。マスク不可能割り込み（NMI）は無効化できないし、多重割り込みを許可するOSでは高優先度割り込みを受け付ける設計になっている。",
          "analogy": "消防や救急（マスク不可能割り込み）は緊急事態のため、どんな状況でも拒否できない。「永久に無効化」は現実には存在しない設計。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "割り込み優先制御では、高優先度の割り込みが発生すると実行中の低優先度処理を中断し先に処理する。多重割り込みにより、割り込みハンドラ実行中にも更に高優先度の割り込みが処理される。NMI（マスク不可能割り込み）は常に処理される。",
      "keyPoint": "高優先度割り込み→低優先度を中断して優先処理（多重割り込み）。NMIは無効化不可。",
      "relatedTopics": ["割り込みハンドラ", "NMI", "RTOS", "プリエンプション", "割り込みベクタ"],
      "studyTip": "割り込みの優先順位は「ハードウェア障害 > タイマー > I/O > ソフト割り込み」という順序が一般的。RTOSと汎用OSで扱い方が異なる点も覚えておこう。"
    },
    "tags": ["割り込み", "割り込み優先制御", "多重割り込み", "NMI", "RTOS", "プリエンプション"]
  },
  {
    "questionId": "q-sh-037",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "software-hardware",
    "topic": "実効アクセス時間",
    "level": 8,
    "question": "ページング方式の仮想記憶システムにおいて、ページテーブルへのアクセス時間が80ナノ秒、主記憶（RAM）へのアクセス時間が100ナノ秒、TLBのヒット率が95%、TLBのアクセス時間が5ナノ秒であるとき、実効メモリアクセス時間（ページテーブルアクセスを含む平均アクセス時間）として正しいものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "約104.75ナノ秒",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "TLBヒット時のアクセス時間（5+100=105ns）とTLBミス時のアクセス時間（5+80+100=185ns）の加重平均を計算すると105×0.95+185×0.05=99.75+9.25=109nsであり、104.75nsは誤り。",
          "analogy": "索引（TLB）を引いて本のページをすぐ見つける場合と、索引が外れて改めて目次（ページテーブル）から調べる場合の平均時間が、この計算で誤った値になっている。"
        }
      },
      {
        "id": "b",
        "text": "約109ナノ秒",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "実効アクセス時間の計算：\n・TLBヒット時：TLBアクセス(5ns) + 主記憶アクセス(100ns) = 105ns\n・TLBミス時：TLBアクセス(5ns) + ページテーブルアクセス(80ns) + 主記憶アクセス(100ns) = 185ns\n・実効時間 = 105×0.95 + 185×0.05 = 99.75 + 9.25 = 109ns",
          "analogy": "図書館の索引カード（TLB）を使えばすぐ本の場所がわかる（105ns）が、索引に載っていない本は司書（ページテーブル）に聞いてから取りに行く（185ns）。95%の確率で索引が使えるとき、平均的に待つ時間が109ns。",
          "deepDive": "TLB（Translation Lookaside Buffer）は仮想アドレス→物理アドレスの変換結果をキャッシュするハードウェアバッファ。TLBヒット時はページテーブルへの追加アクセスが不要なため、大幅に実効アクセス時間を短縮できる。TLBのヒット率（h）、TLBアクセス時間（t）、ページテーブルアクセス時間（p）、主記憶アクセス時間（m）として、実効時間 ＝ (t+m)×h + (t+p+m)×(1-h) という公式で計算する。"
        }
      },
      {
        "id": "c",
        "text": "約185ナノ秒",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "185nsはTLBミス時のアクセス時間（5+80+100）のみの値。ヒット率を考慮した加重平均を求めていないため誤り。常にTLBミスが発生する最悪ケースの値。",
          "analogy": "索引が常に外れると仮定して（ヒット率0%）計算した最悪ケース。95%の確率で索引が使えるという条件を無視している。"
        }
      },
      {
        "id": "d",
        "text": "約100ナノ秒",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "100nsは主記憶アクセス時間のみの値。TLBアクセスやページテーブルアクセスの時間を全く考慮していないため誤り。ページングのオーバーヘッドを無視した計算。",
          "analogy": "本が手元にある（TLBやページテーブル不要）と仮定した計算。実際は索引や目次を引く手間（TLB/ページテーブルアクセス）が加わるため、これより長くなる。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "実効アクセス時間 ＝ (TLBアクセス時間+主記憶時間)×ヒット率 + (TLBアクセス時間+ページテーブル時間+主記憶時間)×(1-ヒット率)。TLBのヒット率が高いほど実効時間は短くなる。",
      "keyPoint": "実効時間 ＝ ヒット時コスト×ヒット率 ＋ ミス時コスト×(1-ヒット率)。TLBはページテーブルアクセスをキャッシュして高速化する。",
      "relatedTopics": ["TLB", "ページテーブル", "仮想記憶", "アドレス変換", "キャッシュメモリ"],
      "studyTip": "実効アクセス時間の計算は「ヒット時の時間×ヒット率 + ミス時の時間×ミス率」の公式を暗記。ヒット率が高いほど実効時間はヒット時の時間に近づく。"
    },
    "tags": ["実効アクセス時間", "TLB", "ページング", "仮想記憶", "アドレス変換", "計算問題"]
  },
  {
    "questionId": "q-sh-038",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "software-hardware",
    "topic": "マルチプロセッサOS",
    "level": 8,
    "question": "マルチプロセッサシステムのOSにおけるSMP（Symmetric Multi-Processing）の説明として、最も適切なものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "SMPでは、各プロセッサが異なるOSを実行し、独立したメモリ空間を持つ非対称な構成を取る。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "SMPは全プロセッサが同一のOSイメージを共有して実行する対称（Symmetric）な構成。各プロセッサが別々のOSを持つ非対称な構成はAMP（Asymmetric Multi-Processing）の説明に近い。",
          "analogy": "SMPは全員が同じルールブック（OS）を共有して平等に仕事をする組織。それぞれが独自のルールで動くのはSMPとは逆の非対称構成。"
        }
      },
      {
        "id": "b",
        "text": "SMPでは、すべてのプロセッサが同一のOSイメージとメモリ空間を共有し、どのプロセッサでもOSのカーネルコードや任意のプロセスを実行できる。",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "SMP（対称型マルチプロセッシング）では、すべてのCPU/コアが同一の物理メモリを共有し、同一のOSカーネルイメージを使用する。どのプロセッサでもカーネルコードを実行でき、OSのスケジューラが任意のプロセス・スレッドを任意のCPUに割り当てる。これにより負荷分散が自然に行われる。",
          "analogy": "SMPは同じマニュアル（OS）を持つ複数の作業員（CPU）が、同じ倉庫（メモリ）を共有して作業する工場。誰がどの仕事をやってもよく、工場長（スケジューラ）が最も効率よく作業を割り振る。",
          "deepDive": "SMPの課題は、複数CPUが同じメモリにアクセスするためのキャッシュコヒーレンシ（MSI/MESI/MOESIプロトコル）の維持とカーネルの排他制御（スピンロック）。多くのコアが同一ロックを取り合うとロックコンテンションが発生しスケーラビリティが低下する。この問題に対処するためNUMA（Non-Uniform Memory Access）アーキテクチャが採用されることもある。"
        }
      },
      {
        "id": "c",
        "text": "SMPではプロセッサ間の通信にネットワークを使用するため、分散システムの一種として分類される。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "SMPはプロセッサ間通信にネットワークを使わず、共有メモリバスやクロスバースイッチで接続する密結合マルチプロセッサシステム。ネットワーク通信を用いるのはMPP（Massively Parallel Processing）やクラスタなどの分散システム。",
          "analogy": "SMPは同じ部屋にいる複数人が直接話し合える（共有メモリ）会議室。分散システムは別の建物にいる人たちが電話（ネットワーク）でやりとりする組織。"
        }
      },
      {
        "id": "d",
        "text": "SMPでは、特定のプロセッサだけがOSカーネルを実行し、他のプロセッサはユーザープロセスの実行のみ許可される。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "特定のプロセッサだけがカーネルを実行するのはMaster-Slaveモデル（AMPに近い設計）の特性。SMPでは対称的にどのプロセッサでもカーネルコードを実行できる。",
          "analogy": "SMPは全員が管理職も現場作業もできる組織（対称）。1人だけが管理職で他は現場専任の組織はSMPではなく非対称マルチプロセッシング。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "SMPはすべてのCPUが同一OSとメモリを共有し、どのCPUでもカーネル・ユーザープロセスを実行できる対称型マルチプロセッサ構成。スケジューラが負荷を自動分散するが、キャッシュコヒーレンシとロックコンテンションが課題。",
      "keyPoint": "SMP＝全CPU共通OS・共有メモリ。誰でもどこでも実行可能（対称的）。キャッシュコヒーレンシとロックが課題。",
      "relatedTopics": ["マルチコアプロセッサ", "キャッシュコヒーレンシ", "NUMA", "スピンロック", "スレッドスケジューリング"],
      "studyTip": "SMP（Symmetric＝対称）とAMP（Asymmetric＝非対称）の違いを「全員平等か役割分担か」でイメージすると覚えやすい。"
    },
    "tags": ["SMP", "マルチプロセッサ", "NUMA", "キャッシュコヒーレンシ", "並列処理", "OS"]
  },
  {
    "questionId": "q-sh-039",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "software-hardware",
    "topic": "ジャーナリングファイルシステム",
    "level": 8,
    "question": "ジャーナリングファイルシステムの説明として、最も適切なものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "ジャーナリングはファイルのバックアップを自動的に別ドライブに作成する機能であり、ドライブ障害時のデータ回復を目的とする。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "ジャーナリングはバックアップ機能ではない。ジャーナリングはファイルシステムへの変更をトランザクションとして先にジャーナル（ログ）に記録することで、電源断などの障害発生時にファイルシステムの一貫性を素早く回復する仕組みである。",
          "analogy": "ジャーナリングは日記（ジャーナル）に「次にやること」を先に書いてから実際の作業をする方法。日記があれば作業が途中で止まっても続きからやり直せる。バックアップとは別の話。"
        }
      },
      {
        "id": "b",
        "text": "ジャーナリングファイルシステムは、ファイルシステムへの変更操作をジャーナル（ログ）に先書きしてからディスクに反映することで、クラッシュ後の整合性回復を高速に行える。",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "ジャーナリングファイルシステム（ext3/ext4、NTFS、APFS、XFSなど）は、メタデータ（またはデータも含む）の変更をトランザクションとしてジャーナル領域に先書き（Write-Ahead Logging）してからディスクのファイルシステム本体に反映する。電源断などでクラッシュが発生しても、ジャーナルを見れば完了していないトランザクションがわかり、再実行または破棄することでファイルシステムを一貫性のある状態に素早く戻せる。",
          "analogy": "ジャーナリングは「作業メモ（ジャーナル）を先に書いてから実作業をする」工程管理。停電でシャットダウンしても作業メモを見れば途中の状態がわかり、やり直しや巻き戻しが素早くできる。メモなし（非ジャーナリング）だと、電気が消えたとき途中だったのか完了したのか不明になる。",
          "deepDive": "ジャーナリングには3つのモード（ext4の場合）がある。（1）writeback：メタデータのみジャーナル、データは書き込み後にジャーナル（高速・低安全）。（2）ordered（デフォルト）：メタデータをジャーナルしデータを先に書く（バランス型）。（3）journal：メタデータ・データ両方をジャーナル（低速・高安全）。クラッシュ後のfsckが不要になる（または大幅短縮される）点がジャーナリングの大きなメリット。"
        }
      },
      {
        "id": "c",
        "text": "ジャーナリングファイルシステムは、すべてのファイルのデータを圧縮して保存することでディスク容量を節約する。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "ジャーナリングはデータ圧縮とは無関係の概念。一部のファイルシステム（Btrfs、ZFSなど）は圧縮機能を持つが、それはジャーナリングとは別の機能。",
          "analogy": "日記（ジャーナル）を書くことと、荷物（ファイル）を圧縮して小さくすることは全く別の話。"
        }
      },
      {
        "id": "d",
        "text": "ジャーナリングはRAIDと同様にデータの冗長化を行うため、ディスク1台の故障時にデータを復元できる。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "ジャーナリングはデータの冗長化・バックアップを行う機能ではなく、ファイルシステムの一貫性を保つための仕組み。ディスク物理障害によるデータ復元はジャーナリングでは対応できず、RAIDやバックアップが必要。",
          "analogy": "日記（ジャーナル）があっても、ノート（ディスク）そのものが燃えたら日記の内容は残らない。ノートのコピーを作る（RAID）のとは別の話。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "ジャーナリングファイルシステムは変更操作をジャーナル（ログ）に先書きしてからディスクに反映するWrite-Ahead Logging方式を用いる。電源断等のクラッシュ後もジャーナルを参照して素早くファイルシステムの整合性を回復できる。",
      "keyPoint": "ジャーナリング＝変更の先書きログ（WAL）→クラッシュ後の高速整合性回復。バックアップやRAIDとは別概念。",
      "relatedTopics": ["ext4", "NTFS", "APFS", "Write-Ahead Logging", "fsck", "トランザクション"],
      "studyTip": "「日記（ジャーナル）を書いてから行動する」イメージが核心。ジャーナリングが守るのは「データの整合性」であり「物理障害からの復元」ではない点を混同しないこと。"
    },
    "tags": ["ジャーナリング", "ファイルシステム", "WAL", "ext4", "NTFS", "クラッシュ耐性", "トランザクション"]
  },
  {
    "questionId": "q-sh-040",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "software-hardware",
    "topic": "ハードウェア抽象化層",
    "level": 8,
    "question": "HAL（Hardware Abstraction Layer：ハードウェア抽象化層）に関する説明として、最も適切なものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "HALはアプリケーションソフトウェアが直接ハードウェアを制御するために提供されるAPIである。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "HALはアプリケーションが直接ハードウェアを制御するAPIではなく、OSとハードウェアの間に位置してハードウェアの違いをOSから隠蔽する層。アプリケーションは通常OSのシステムコールを通じてハードウェアにアクセスし、HALは意識しない。",
          "analogy": "HALはOSとハードウェアの間の通訳（翻訳者）。アプリは通訳の存在を知らずにOSと話すだけで、OSが通訳を通じてハードウェアに指示する。"
        }
      },
      {
        "id": "b",
        "text": "HALはOSとハードウェアの間に位置し、ハードウェアの差異をOSから隠蔽することで、OSがハードウェアに依存せずに動作できるようにする層である。",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "HAL（ハードウェア抽象化層）はOSカーネルとハードウェアの間に位置するソフトウェア層であり、異なるハードウェアアーキテクチャやプラットフォームの差異を抽象化・隠蔽する。これによりOSのカーネルコードはHALが提供する統一インターフェースを使って動作できるため、ハードウェアが変わっても主要なカーネルコードを変更せずにポーティングが容易になる。",
          "analogy": "HALは電化製品と電源の間にある「電圧アダプタ」のようなもの。日本（OSカーネル）は100Vの電気しか使えないが、アダプタ（HAL）があれば海外のコンセント（異なるハードウェア）でも同じ電化製品を使える。",
          "deepDive": "WindowsのHAL（hal.dll）はI/Oバス・割り込みコントローラ・DMAなどのハードウェア差異を吸収し、Windowsカーネルがx86・x64・ARM等で共通のコードで動作できるようにする。AndroidのHAL（HIDL/AIDL）はLinuxカーネルの上にあり、カメラ・センサー・GPUなどのSoC固有実装をAndroid OSから隠蔽することで様々なスマートフォンハードウェアでAndroidが動作できる設計を実現する。"
        }
      },
      {
        "id": "c",
        "text": "HALはネットワークプロトコルを抽象化し、アプリケーションが特定のネットワーク規格に依存せずに通信できるようにする層である。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "ネットワークプロトコルを抽象化するのはソケットAPIや通信ミドルウェアの役割であり、HALではない。HALはハードウェア全般（CPU、バス、割り込み等）を対象とした抽象化層。",
          "analogy": "HALは電化製品のアダプタ（ハードウェア全般）。ネットワーク通信の翻訳（プロトコル抽象化）は別の通訳の仕事。"
        }
      },
      {
        "id": "d",
        "text": "HALはハードウェアの性能を最大限引き出すために、OSを介さずハードウェアに直接アクセスする高速化技術である。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "HALはOSを「バイパス」するための技術ではなく、OSとハードウェアの間を仲介する「抽象化」のための技術。OSを介さない直接アクセスはHALの目的とは逆方向の設計思想。",
          "analogy": "アダプタ（HAL）は電気系統を安全につなぐためのもの。アダプタを使わずに直接配線する（OSバイパス）のは全く別の、むしろ危険なやり方。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "HAL（ハードウェア抽象化層）はOSカーネルとハードウェアの間に位置し、ハードウェアの差異を隠蔽する。これによりOSは多様なハードウェアプラットフォームで共通コードを使って動作できる（ポータビリティの向上）。WindowsのHALやAndroidのHALが代表例。",
      "keyPoint": "HAL＝OSとハードウェアの間の抽象化層。ハードウェアの差異を隠蔽してOSのポータビリティを高める。",
      "relatedTopics": ["デバイスドライバ", "BIOS/UEFI", "カーネル", "ポーティング", "Android HAL"],
      "studyTip": "HALは「翻訳者・通訳者」のイメージ。OSがどんなハードウェアでも同じ言葉（インターフェース）で話しかけられるように、HALがその都度ハードウェアの言語に翻訳してくれる。"
    },
    "tags": ["HAL", "ハードウェア抽象化", "OS設計", "ポータビリティ", "デバイスドライバ", "Windows", "Android"]
  }
]
