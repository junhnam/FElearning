[
  {
    "questionId": "q-db-026",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "database",
    "topic": "CAP定理とDB",
    "level": 9,
    "question": "CAP定理に関する説明として、正しいものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "分散システムは「一貫性」「可用性」「分断耐性」の3つの特性をすべて同時に満たすことができる",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "CAP定理の核心はまさにこの反対です。分散システムでは「一貫性（Consistency）」「可用性（Availability）」「分断耐性（Partition tolerance）」の3つを同時に満たすことは不可能であり、ネットワーク障害（分断）が発生した際には一貫性か可用性のどちらかを犠牲にしなければなりません。",
          "analogy": "遠距離恋愛で「毎日連絡（可用性）」「完璧な情報共有（一貫性）」「携帯圏外でも成立（分断耐性）」の3つを同時に満たすのが不可能なのと同じです。"
        }
      },
      {
        "id": "b",
        "text": "ネットワーク分断が発生した場合、一貫性と可用性のどちらかを犠牲にしなければならない",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "CAP定理（Brewer の定理）は、分散システムが同時に満たせるのはC（一貫性）・A（可用性）・P（分断耐性）のうち2つまでであることを証明したものです。実用的な分散システムではネットワーク分断（P）は避けられないため、CかAのどちらかを選択する設計になります。CP系（HBase, ZooKeeper）は一貫性優先、AP系（Cassandra, CouchDB）は可用性優先です。",
          "analogy": "災害時の情報伝達に例えると、「正確な情報のみ発信（一貫性）」と「とにかく何かを発信し続ける（可用性）」は同時に満たすのが難しい状況があります。通信障害（分断）があるなら、どちらかを妥協しなければなりません。",
          "deepDive": "CAP定理の実践的な理解：①CA系（MySQLのような単一ノード構成）：分断耐性を捨てている ②CP系：分断時は応答を停止して一貫性を保つ（例：銀行のATM ③AP系：分断時も応答を続けるが内容が古い可能性がある（例：SNSのタイムライン）。近年はPACELC定理（分断がない通常時もレイテンシと一貫性のトレードオフがある）も提唱されています。"
        }
      },
      {
        "id": "c",
        "text": "CAP定理はリレーショナルデータベースにのみ適用される理論である",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "CAP定理は分散システム全般に適用される理論であり、リレーショナルデータベースに限りません。NoSQLデータベースや分散ファイルシステムなど、あらゆる分散システムの設計原則として参照されます。",
          "analogy": "「車には4つのタイヤが必要」というルールが軽自動車にも大型トラックにも適用されるように、CAP定理は種類を問わず分散システム全体に適用されます。"
        }
      },
      {
        "id": "d",
        "text": "一貫性（C）は「全ノードが常に最新のデータを書き込めること」を意味する",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "CAP定理の一貫性（C）は「すべてのノードで読み取りが同一の最新データを返すこと」を意味します。「書き込めること」ではなく「読み取り時に古いデータが見えないこと（線形化可能性）」が正しい定義です。",
          "analogy": "図書館の本が全支店で同じ最新版に更新されていれば、どの支店で借りても同じ内容が読めます（読み取り一貫性）。書き込み権限の話ではありません。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "CAP定理は分散システムにおいてC（一貫性）・A（可用性）・P（分断耐性）の3つを同時には満たせないという定理です。ネットワーク分断時はCとAのどちらかを選択する設計になります。",
      "keyPoint": "CAP定理＝C・A・P のうち同時に満たせるのは2つまで。分散システムではP必須のためCとAのトレードオフ。",
      "relatedTopics": ["結果整合性", "BASE特性", "NoSQLデータベース", "PACELC定理"],
      "studyTip": "CP系（HBase, MongoDB）とAP系（Cassandra, DynamoDB）の代表的なDBを具体例として覚えると理解が深まります。"
    },
    "tags": ["CAP定理", "分散システム", "一貫性", "可用性", "分断耐性"]
  },
  {
    "questionId": "q-db-027",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "database",
    "topic": "分散トランザクション",
    "level": 9,
    "question": "2相コミットプロトコル（2PC）に関する説明として、正しいものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "2相コミットでは、コーディネータが停止してもすべての参加者が独立してコミットを継続できる",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "2相コミットの重大な問題の一つが「コーディネータの単一障害点（SPOF）」です。コーディネータが第2フェーズ中に停止すると、参加者はコミットすべきかロールバックすべきか判断できず、ロック保持状態でブロックされます。これが2PCの主要な弱点です。",
          "analogy": "全員での賛否投票で、進行役（コーディネータ）が結果を集計する前に倒れてしまうと、参加者全員がその場で動けなくなってしまうのと同じです。"
        }
      },
      {
        "id": "b",
        "text": "第1フェーズ（準備フェーズ）でコーディネータが全参加者から「OK」を得た後、第2フェーズでコミットを指示する",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "2相コミット（2PC）の流れ：第1フェーズ（Prepare）でコーディネータが全参加者にコミット準備を要求し、全参加者が「準備完了（Prepared）」を返した場合のみ、第2フェーズ（Commit）でコミットを指示します。1つでも「NG」があればコーディネータはロールバックを指示します。これにより分散環境でのACIDを保証します。",
          "analogy": "結婚式の「誓いの言葉」のようなものです。神父が「誓いますか？」と聞き（第1フェーズ）、新郎新婦の両方が「誓います」と言った場合のみ「誓いは成立しました」（第2フェーズ：コミット）と宣言します。どちらかが「誓いません」と言えばコミット（結婚）は成立しません（ロールバック）。",
          "deepDive": "2PCの問題点：①ブロッキング問題：コーディネータ障害時に参加者がブロック ②パフォーマンス：2往復の通信が必要でレイテンシが高い ③適用範囲：XAプロトコル（分散トランザクション標準）で実装される。3相コミット（3PC）はブロッキング問題を解消しようとした改良版ですが、さらに複雑で完全な解決にはなっていません。PaxosやRaftなどのコンセンサスアルゴリズムが現代的な解決策として用いられています。"
        }
      },
      {
        "id": "c",
        "text": "2相コミットは単一のデータベースサーバー内でのトランザクション管理に使用されるプロトコルである",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "2相コミットは複数の独立したデータベースサーバー（分散システム）にまたがるトランザクションを調整するプロトコルです。単一サーバー内ではACIDはDBMSが直接管理するため、2PCは不要です。",
          "analogy": "同じ会社内の決裁（単一サーバー）なら担当者1人で決められますが、複数の会社（複数サーバー）をまたぐ取引では、全社の合意を得るプロセス（2PC）が必要です。"
        }
      },
      {
        "id": "d",
        "text": "第1フェーズでコミットが完了し、第2フェーズで結果の通知のみを行う",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "第1フェーズはコミットの準備（Prepare）であり、実際のコミットではありません。コミットは第2フェーズで行われます。第1フェーズはあくまで「コミットできる準備が整ったか」を確認する段階です。",
          "analogy": "「料理の材料が全部揃っているか確認する（第1フェーズ：準備）」と「実際に料理を完成させる（第2フェーズ：コミット）」を逆に理解しています。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "2相コミット（2PC）は分散トランザクションを実現するプロトコルです。第1フェーズで全参加者の準備確認、第2フェーズでコミットまたはロールバックの指示を行います。コーディネータ障害によるブロッキングが弱点です。",
      "keyPoint": "2PC＝第1フェーズ（準備確認）→全員OK→第2フェーズ（コミット指示）。1つでもNGならロールバック。",
      "relatedTopics": ["分散トランザクション", "XAプロトコル", "3相コミット", "Paxos", "Raft"],
      "studyTip": "2PCの「ブロッキング問題」（コーディネータ障害でデータが宙吊りになる）は試験頻出の弱点なので必ず押さえましょう。"
    },
    "tags": ["2相コミット", "2PC", "分散トランザクション", "コーディネータ", "準備フェーズ"]
  },
  {
    "questionId": "q-db-028",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "database",
    "topic": "多版同時実行制御",
    "level": 9,
    "question": "多版同時実行制御（MVCC）の説明として、正しいものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "MVCCでは、データの書き込み時に読み取りトランザクションを強制的に中断させる",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "MVCCの最大の特徴は、書き込み操作が読み取り操作をブロックしないことです。書き込み時は古いバージョンのデータを残しながら新しいバージョンを作成するため、読み取りトランザクションは中断されず古いバージョンを読み続けられます。",
          "analogy": "図書館で本を改訂中でも、古い版の本は引き続き貸し出せます。改訂作業が読者の利用を止めることはありません。"
        }
      },
      {
        "id": "b",
        "text": "データの各バージョンにタイムスタンプを持たせ、トランザクション開始時点のスナップショットを読み取ることで、読み取りと書き込みの競合を最小化する",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "MVCC（Multi-Version Concurrency Control）は、データの更新時に古いバージョンを破棄せず、バージョン番号またはタイムスタンプとともに保持します。各トランザクションは開始時点のスナップショット（コンシステントスナップショット）を読むため、書き込みトランザクションが読み取りをブロックしません（読み取りはロックを取得しない）。PostgreSQLやMySQLのInnoDBなどがMVCCを採用しています。",
          "analogy": "Google ドキュメントの「変更履歴」機能のようなものです。誰かが文書を編集中でも、他の人は「編集前の版」を参照できます。それぞれが自分が見始めたときの版を閲覧できるため、編集中でも閲覧が妨げられません。",
          "deepDive": "MVCCの実装の詳細：①トランザクション開始時のスナップショット（txid）より古いコミット済みバージョンを可視範囲とする ②古いバージョンはVACUUM（PostgreSQL）やPURGE（MySQL）などのバックグラウンド処理で定期的に削除 ③ファントムリードをMVCCで防ぐには「述語ロック」や「SSI（Serializable Snapshot Isolation）」が必要。MVCCは読み取り集中型ワークロードでパフォーマンスに優れます。"
        }
      },
      {
        "id": "c",
        "text": "MVCCはデータを1バージョンしか保持しないため、ストレージ消費量が少ない",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "MVCCは「多版（Multi-Version）」という名前の通り、データの複数バージョンを保持します。そのため通常のロックベースの同時実行制御より多くのストレージを消費します。古いバージョンは定期的なガベージコレクション（VACUUMなど）で削除されます。",
          "analogy": "本の改訂版を出すたびに旧版も保管するため、書庫の本の冊数は増えていきます。1冊だけ保管するよりストレージが多く必要です。"
        }
      },
      {
        "id": "d",
        "text": "MVCCを使用すると、すべての異常現象（ダーティリード、ファントムリード等）が自動的に防止される",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "MVCCはダーティリードや反復不能読み取りを防ぐのに効果的ですが、ファントムリードはMVCCだけでは完全に防げません（述語ロックやSerializable Snapshot Isolationが必要です）。また、書き込み-書き込みの競合はMVCCだけでは解決できません。",
          "analogy": "鍵を付ければ泥棒の大半は防げますが、鍵だけですべての侵入を防ぐのは難しいように、MVCCも万能ではありません。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "MVCCはデータの複数バージョンを保持し、トランザクション開始時点のスナップショットを読み取ることで、読み取りと書き込みの競合を最小化する同時実行制御手法です。",
      "keyPoint": "MVCC＝複数バージョン保持→読み取りが書き込みをブロックしない→高い並行性",
      "relatedTopics": ["トランザクション分離レベル", "スナップショット分離", "VACUUM", "楽観的ロック"],
      "studyTip": "MVCCを採用する代表的なDBMS（PostgreSQL, MySQL InnoDB, Oracle）を覚え、ロックベースの同時実行制御との違いを整理しましょう。"
    },
    "tags": ["MVCC", "多版同時実行制御", "スナップショット", "並行性制御", "トランザクション分離"]
  },
  {
    "questionId": "q-db-029",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "database",
    "topic": "OLAPとデータウェアハウス",
    "level": 9,
    "question": "OLAPとOLTPの違いに関する説明として、正しいものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "OLAPは少量のデータへの高速な挿入・更新・削除が主な用途であり、OLTPは大量データの分析が主な用途である",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "OLAPとOLTPの用途が逆です。OLTP（Online Transaction Processing）は日常業務の少量データへの高速なCRUD操作（受注・決済など）が用途です。OLAP（Online Analytical Processing）は大量の履歴データに対する複雑な集計・分析が用途です。",
          "analogy": "コンビニのレジ（OLTP）は1件ずつ素早い会計処理が得意で、本社の経営分析部門（OLAP）は全店舗の年間売上傾向を分析します。"
        }
      },
      {
        "id": "b",
        "text": "OLTPはトランザクション処理（業務系）、OLAPはデータ分析（分析系）に特化したシステムである",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "OLTP（Online Transaction Processing）は日常業務のトランザクション処理（受注、決済、在庫更新など）に特化し、少量データへの高速な読み書きが特徴です。OLAP（Online Analytical Processing）は経営分析や意思決定支援のために大量の履歴データを多次元的に集計・分析するシステムで、スター型スキーマやスノーフレーク型スキーマを使うデータウェアハウス（DWH）上で動作することが多いです。",
          "analogy": "OLTP は現金自動預払機（ATM）で「今1万円引き出す」という即時処理を担当し、OLAP は銀行の経営会議で「過去5年間の地域別ATM利用傾向を分析する」ような業務を担当します。",
          "deepDive": "OLAPの3つの操作：①スライス（1次元を固定して切り出す）②ダイス（複数次元で絞り込む）③ドリルダウン/ロールアップ（詳細化/集約）。データウェアハウスの特徴：主題指向、統合、非揮発的、時変。ETL（Extract-Transform-Load）プロセスでOLTPのデータをDWHに取り込みます。"
        }
      },
      {
        "id": "c",
        "text": "OLAPとOLTPは同じデータベースサーバー上で実行することが推奨されている",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "OLAPとOLTPを同一サーバーで実行すると、OLAP の大規模集計処理がOLTP の業務応答に悪影響を与えます。そのため通常は分離して構築します（ETLでOLTPからDWHへデータを転送）。HTAP（Hybrid Transactional/Analytical Processing）はこれを1つのシステムで実現する新しいアーキテクチャです。",
          "analogy": "工場の生産ライン（OLTP）と品質管理の統計分析室（OLAP）を同じ場所にすると、分析作業が生産の邪魔になります。通常は別々に設置します。"
        }
      },
      {
        "id": "d",
        "text": "OLAPはリアルタイム性が最重要であり、データの鮮度が数分以内でなければならない",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "OLAPはリアルタイム性よりも大量データの集計・分析精度が重要です。伝統的なDWHではETL処理により日次・週次でデータが更新されるバッチ処理が一般的でした。近年はリアルタイム分析（Streaming Analytics）も普及していますが、OLAPの本質はリアルタイム性ではなく多次元分析にあります。",
          "analogy": "経営会議での年間売上レポートは昨年のデータを分析するもので、リアルタイムの秒単位データは必要ありません。リアルタイム性が重要なのはOLTPの方です。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "OLTPは業務系の少量データへの高速トランザクション処理、OLAPは分析系の大量データへの複雑な集計・分析処理です。通常は別システム（DWH）に分離して構築します。",
      "keyPoint": "OLTP＝日常業務（受注・決済）の即時処理。OLAP＝大量履歴データの多次元分析。",
      "relatedTopics": ["データウェアハウス", "ETL", "スタースキーマ", "HTAP", "BI（ビジネスインテリジェンス）"],
      "studyTip": "OLTPとOLAPの違いを「件数・更新頻度・応答時間・データ量」の4軸で比較する表を作って覚えましょう。"
    },
    "tags": ["OLAP", "OLTP", "データウェアハウス", "DWH", "多次元分析"]
  },
  {
    "questionId": "q-db-030",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "database",
    "topic": "ビッグデータ処理",
    "level": 9,
    "question": "ビッグデータの特徴を表す「3V」として、正しいものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "Volume（量）、Velocity（速度）、Variety（多様性）",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "ビッグデータの3Vは①Volume（膨大なデータ量：ペタバイト・エクサバイト級）②Velocity（データの生成・処理速度：リアルタイムストリームなど）③Variety（データの多様性：構造化・半構造化・非構造化データ）です。これらはGartnerが提唱したビッグデータの定義として広く使われています。",
          "analogy": "SNSに例えると、毎日何億件も投稿される（Volume）、リアルタイムでトレンドが変わる（Velocity）、テキスト・画像・動画・位置情報など様々な形式がある（Variety）という3つの特徴があります。",
          "deepDive": "近年は3Vに加えてVeracity（正確性：データ品質のばらつき）やValue（価値：ビジネス価値の創出）を含めた「5V」で定義されることもあります。ビッグデータ処理基盤：Hadoop（分散バッチ処理）、Spark（インメモリ高速処理）、Kafka（ストリーム処理）、Flink（ストリーム処理）などが代表的なエコシステムです。"
        }
      },
      {
        "id": "b",
        "text": "Volume（量）、Visibility（可視性）、Validity（有効性）",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "ビッグデータの3Vは「Volume・Velocity・Variety」です。VisibilityとValidityはビッグデータの代表的な3Vには含まれません。",
          "analogy": "ビッグデータの3Vを「V・V・V」と覚えるだけでなく、各単語の意味（量・速度・多様性）をセットで覚えることが重要です。"
        }
      },
      {
        "id": "c",
        "text": "Volume（量）、Versatility（汎用性）、Verification（検証）",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "VersatilityとVerificationはビッグデータの3Vに含まれません。正しい3VはVelocity（速度）とVariety（多様性）です。",
          "analogy": "試験で出題される頻出のキーワードは正確に覚える必要があります。似た語感のVで始まる単語に惑わされないようにしましょう。"
        }
      },
      {
        "id": "d",
        "text": "Virtualization（仮想化）、Velocity（速度）、Variety（多様性）",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "Virtualization（仮想化）はビッグデータの3Vに含まれません。3VのうちVolumeの代わりに仮想化を当てているため誤りです。データ量（Volume）はビッグデータの最も根本的な特徴の一つです。",
          "analogy": "「ビッグ」データというくらいですから、「量（Volume）が多い」というのは外せない特徴です。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "ビッグデータの3Vは「Volume（量）」「Velocity（速度）」「Variety（多様性）」です。膨大な量・高速な生成・多様な形式のデータを扱う技術・手法の総称がビッグデータです。",
      "keyPoint": "ビッグデータ3V＝Volume（量）・Velocity（速度）・Variety（多様性）",
      "relatedTopics": ["Hadoop", "Spark", "NoSQL", "データレイク", "ストリーム処理"],
      "studyTip": "3VにVeracity（正確性）とValue（価値）を加えた5Vも覚えておくと応用問題に対応できます。"
    },
    "tags": ["ビッグデータ", "3V", "Volume", "Velocity", "Variety"]
  },
  {
    "questionId": "q-db-031",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "database",
    "topic": "MapReduce",
    "level": 9,
    "question": "MapReduceプログラミングモデルに関する説明として、正しいものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "MapReduceではMapフェーズとReduceフェーズが必ず並列して同時実行される",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "MapReduceではMapフェーズが完了した後にReduceフェーズが開始されます。Mapの全出力（またはその大部分）が揃った後にReduceが実行されるため、同時並列ではなく逐次的な依存関係があります。ただし各フェーズ内では複数のタスクが並列実行されます。",
          "analogy": "料理の工程に例えると、まず食材を切り刻む（Map）工程を全員で並列にこなし、それが終わってから全員の切り刻んだ食材をまとめて調理する（Reduce）工程に進みます。切る作業と調理を同時並行はしません。"
        }
      },
      {
        "id": "b",
        "text": "Mapフェーズで各データ要素をキーと値のペアに変換し、Reduceフェーズで同一キーのデータを集約・集計する",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "MapReduceはGoogleが提唱した分散処理モデルです。①Mapフェーズ：入力データを分割して各ノードで並列処理し、（キー、値）ペアを出力 ②Shuffleフェーズ：同一キーのデータを同一ノードに集める ③Reduceフェーズ：同一キーのデータをまとめて集計・変換して最終結果を出力。大量データを多数のノードで並列分散処理するのに適しています。",
          "analogy": "世界規模の選挙開票に例えると、Map（各投票所が候補者ごとに票を数える）→Shuffle（候補者ごとに各地の集計を中央に集める）→Reduce（候補者ごとの全国集計を行う）という流れです。",
          "deepDive": "MapReduceの典型例：単語カウント。Map：テキストの各単語をキーに（'hello',1）を出力 → Shuffle：同じキーのペアを同一ノードへ → Reduce：（'hello', [1,1,1]）→ （'hello', 3）。ApacheHadoopのMapReduceはこのモデルを実装した代表的なフレームワークです。ただし処理ごとにディスクI/Oが発生するため、Apache Sparkのインメモリ処理が後継として広く使われています。"
        }
      },
      {
        "id": "c",
        "text": "MapReduceは単一サーバー上での処理を前提として設計されており、分散処理には対応していない",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "MapReduceは分散処理を前提として設計されたフレームワークです。Googleのデータセンターで数千台のサーバーに跨る大規模データを並列処理することを目的として考案されました。",
          "analogy": "MapReduceは「大人数で手分けして作業する」ためのモデルです。1人でやることを想定していません。"
        }
      },
      {
        "id": "d",
        "text": "Reduceフェーズでは新しいデータをデータベースに追加する操作のみが可能である",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "Reduceフェーズは「データの追加のみ」という制限はありません。集計（合計・平均）、フィルタリング、結合、変換など、様々な処理が可能です。Reduceフェーズの役割は「同一キーのデータを集約して最終的な出力を生成すること」です。",
          "analogy": "集計担当者（Reduce）がやることは単純な追加だけでなく、合計を出したり、平均を計算したり、比較したりと多様な作業ができます。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "MapReduceはMap（データをキーと値ペアに変換）→Shuffle（同一キーをまとめる）→Reduce（集約・集計）という分散処理モデルです。大量データの並列処理に適しています。",
      "keyPoint": "MapReduce＝Map（分散変換）→Shuffle（キーでまとめ）→Reduce（集約）の3段階",
      "relatedTopics": ["Hadoop", "Apache Spark", "分散処理", "ビッグデータ", "HBase"],
      "studyTip": "単語カウントの例でMapReduceの3フェーズの流れを手で追って理解すると記憶に定着します。"
    },
    "tags": ["MapReduce", "Map", "Reduce", "Shuffle", "分散処理", "Hadoop"]
  },
  {
    "questionId": "q-db-032",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "database",
    "topic": "列指向DB",
    "level": 9,
    "question": "列指向データベース（カラムナーDB）が行指向データベースと比較して特に優れているシナリオはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "1件の注文を素早くINSERTする業務系処理",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "少量のレコードへの挿入・更新・削除のような業務系トランザクション処理（OLTP）では、1行のデータをまとめて格納できる行指向DBの方が効率的です。列指向DBでは1行のデータが複数の列ストアに分散して書かれるため、書き込みオーバーヘッドが大きくなります。",
          "analogy": "1枚の注文書（行）を丸ごとファイルに入れる（行指向）方が、注文書の項目ごとに別々のファイルに分けて保存する（列指向）より素早く処理できます。"
        }
      },
      {
        "id": "b",
        "text": "全社員の「給与」列だけを集計するような大規模分析クエリ",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "列指向DBは特定の列のデータをディスク上でまとめて格納するため、「全社員の給与の平均値を求める」ような特定列だけの集計処理で圧倒的に効率的です。必要な列だけを読み込めばよく、他の列（氏名・住所など）のI/Oが発生しません。また、同じ型のデータが連続するため圧縮効率も高くなります。",
          "analogy": "住所録（社員台帳）で全員の「給与」だけを一覧にしたいとき、列指向は給与の欄（1列）だけを読めばOK。行指向では田中さんの全情報（名前・住所・給与・部署…）→佐藤さんの全情報→…と全行を読む必要があります。列指向は「欄を縦に読む本」のようなものです。",
          "deepDive": "列指向DBの代表製品：Amazon Redshift, Google BigQuery, Apache Parquet（ストレージフォーマット）, Apache Cassandra（ハイブリッド）。圧縮技術：同一型・類似値が連続するため、ランレングス符号化・辞書符号化などが高効率で適用できます。OLAP用途でTB～PB規模のデータを扱う場合に選択されます。"
        }
      },
      {
        "id": "c",
        "text": "特定の顧客IDの注文レコードを主キーで素早く1件検索する処理",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "特定の1レコードを主キーで検索する場合、その行の全列データをまとめて格納している行指向DBの方が効率的です。列指向DBでは同じ行の各列が別の場所に格納されているため、1レコードの全情報を取得するには複数の列ストアを結合する必要があります。",
          "analogy": "田中さん（特定の1人）のすべての情報を取り出すには、行指向の「田中さんのページ1枚」を取り出す方が、列指向の「全員の名前ページから田中を探し、全員の住所ページから田中を探し…」より素早いです。"
        }
      },
      {
        "id": "d",
        "text": "トランザクションの整合性が求められるATM引き出し処理",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "ATMの引き出し処理のような高いトランザクション整合性（ACID）と高速な少量データ操作が求められる処理は、行指向のリレーショナルDBが適しています。列指向DBはACIDトランザクションに最適化されておらず、OLAP用途向けです。",
          "analogy": "精密な瞬時の決済処理（OLTP）は行指向DBの得意分野で、大量データの分析（OLAP）は列指向DBの得意分野です。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "列指向DBは特定列の大量データを集計するOLAP系クエリに最適です。同一列のデータを連続して格納するため、集計処理のI/O量が大幅に削減でき、圧縮効率も高くなります。",
      "keyPoint": "列指向DB＝特定列の大規模集計（OLAP）に最適。行指向DB＝1行の全列操作（OLTP）に最適。",
      "relatedTopics": ["行指向DB", "OLAP", "Amazon Redshift", "Apache Parquet", "圧縮"],
      "studyTip": "行指向と列指向のデータ格納の違いを図で理解し、得意なクエリパターン（OLTP vs OLAP）の違いを整理しましょう。"
    },
    "tags": ["列指向DB", "カラムナーDB", "行指向DB", "OLAP", "集計"]
  },
  {
    "questionId": "q-db-033",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "database",
    "topic": "インメモリDB",
    "level": 9,
    "question": "インメモリデータベース（In-Memory Database）の特徴として、最も正しいものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "ディスクI/Oがないため処理速度が向上するが、サーバー停止時にデータがすべて消失する",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "前半の「ディスクI/Oがなく処理速度が向上する」は正しいですが、後半の「データがすべて消失する」は誤りです。多くのインメモリDBはWALへの書き込みやスナップショットによるディスク永続化、レプリケーションなどの耐久性機構を備えており、停止後もデータを復元できます（Redisの永続化オプションなど）。",
          "analogy": "ホワイトボードに書いた内容（メモリ）は電源を切ると消えてしまいますが、定期的に写真を撮っておけば（スナップショット）復元できます。"
        }
      },
      {
        "id": "b",
        "text": "データをメインメモリ上に配置してディスクI/Oを排除することで、ディスク型DBと比べて大幅な高速化を実現する",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "インメモリDBはデータをRAM上に配置し、ディスクへのランダムアクセスを排除することで、ディスクアクセス（マイクロ秒〜ミリ秒）に比べてメモリアクセス（ナノ秒）が数十〜数百倍高速なことを利用します。セッション管理、キャッシュ、リアルタイムランキング、リアルタイム分析などに使われます。代表的な製品にRedis、Memcached、Apache Igniteがあります。",
          "analogy": "本棚から本を取り出す（ディスクアクセス）のと、すでに手元に広げてある本を読む（メモリアクセス）を比べると、手元の本を読む方が格段に速いです。インメモリDBは常に全データを手元（メモリ）に広げておくイメージです。",
          "deepDive": "Redisの永続化オプション：①RDB（スナップショット）：指定間隔でメモリをディスクに書き出す ②AOF（Append Only File）：全書き込み操作をログに記録 ③両方を組み合わせる方法もある。インメモリDBの限界：メモリ容量がデータサイズの上限（コスト面でディスクより高い）。近年はHybridメモリ（NVMEなどの不揮発性メモリ）を使ったデータベースも登場しています。"
        }
      },
      {
        "id": "c",
        "text": "インメモリDBはキャッシュ専用技術であり、プライマリーDBとしては使用できない",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "インメモリDBはキャッシュ専用ではなく、プライマリーDBとしても使用されます。Redisは単なるキャッシュとして使われることもありますが、セッションストア、リアルタイムランキング、メッセージキューなど独立したプライマリーDBとして使われることも多いです。SAP HANAやVoltDBはプライマリーインメモリDBとして設計されています。",
          "analogy": "付箋（メモリ）は「メモ書き」だけでなく、整理して管理すれば「本格的な管理台帳」にもなれます。"
        }
      },
      {
        "id": "d",
        "text": "インメモリDBではSQL（構造化照会言語）は使用できない",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "多くのインメモリDBはSQLをサポートしています。SAP HANA、VoltDB、MemSQLなどはSQLによるクエリが可能です。ただしRedisのようにデータ構造指向のAPIを使うインメモリDBもあります。SQLの使用可否はインメモリかどうかではなく、DBMSの設計に依存します。",
          "analogy": "高速道路（インメモリ）でも一般道（ディスク型）でも同じ交通ルール（SQL）を適用できます。道路の種類とルールは別の話です。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "インメモリDBはデータをRAMに配置してディスクI/Oを排除することで高速化を実現します。永続化機構（スナップショット・WAL）によりデータ保全も可能です。",
      "keyPoint": "インメモリDB＝全データをRAMに保持→ディスクI/O排除→高速。永続化オプションでデータ保全も可能。",
      "relatedTopics": ["Redis", "Memcached", "SAP HANA", "キャッシュ", "永続化"],
      "studyTip": "RedisのRDB（スナップショット）とAOF（ログ）の2つの永続化方式の違いを覚えておくと応用力が上がります。"
    },
    "tags": ["インメモリDB", "Redis", "高速化", "永続化", "キャッシュ"]
  },
  {
    "questionId": "q-db-034",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "database",
    "topic": "NewSQL",
    "level": 10,
    "question": "NewSQLデータベースの説明として、最も正しいものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "NewSQLはNoSQLの別名であり、リレーショナルデータベースとは無関係なシステムである",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "NewSQLはNoSQLとは異なるカテゴリです。NoSQLはACIDを犠牲にしてスケーラビリティを追求しましたが、NewSQLはSQLとACIDを維持しながらNoSQLレベルの水平スケーラビリティを実現することを目指した新世代のリレーショナルDBMSです。",
          "analogy": "NoSQLが「古い車を捨てて電動バイクに変えた」なら、NewSQLは「同じ見た目の車のまま電動エンジンに換装した」イメージです。"
        }
      },
      {
        "id": "b",
        "text": "NewSQLはSQLインターフェースとACIDトランザクションを維持しながら、水平スケーラビリティを実現する新世代RDBMSである",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "NewSQLは「SQLの使い勝手とACID保証（従来のRDBMSの強み）」と「NoSQLレベルの水平スケールアウト（大量データ・高スループット）」の両立を目指したデータベースシステムの総称です。代表的な製品にGoogle Spanner、CockroachDB、TiDB、VoltDBなどがあります。分散SQLとも呼ばれます。",
          "analogy": "従来のRDBMS（高い整合性・スケールしにくい）とNoSQL（スケールしやすい・整合性が弱い）の「いいとこどり」をしたのがNewSQLです。高層ビルの強度と柔軟性を兼ね備えた新素材で作ったビルのようなものです。",
          "deepDive": "NewSQLの主要技術：①グローバル一貫スナップショット（TrueTime：Spannerが採用する分散同期技術）②Paxos/Raftによる分散コンセンサス ③分散トランザクション（2PCの改良版）④シャーディングの自動化。Google Spannerは時刻同期（原子時計＋GPS）を用いた「外部一貫性」を実現した画期的なシステムです。"
        }
      },
      {
        "id": "c",
        "text": "NewSQLはACIDを諦め、結果整合性を採用することでスケーラビリティを実現している",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "結果整合性を採用してスケーラビリティを実現しているのはNoSQL（AP系）の特徴です。NewSQLはACIDを維持したままスケーラビリティを達成することを目標としている点で、NoSQLとは根本的に異なります。",
          "analogy": "NoSQLは「正確さを少し妥協して速さを取る」アプローチ、NewSQLは「正確さも速さも諦めない」アプローチです。"
        }
      },
      {
        "id": "d",
        "text": "NewSQLはSQL:1999以降に標準化された新しいSQL規格の総称である",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "NewSQLはSQL規格の名前ではなく、分散スケーラブルなデータベースシステムのカテゴリ（製品群）の総称です。SQL規格（ISO/IEC）とは無関係です。",
          "analogy": "「NewSQL」は「新しいSQLという規格書」ではなく、「新しい世代のSQLデータベース製品のジャンル名」です。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "NewSQLはSQLとACIDを維持しながらNoSQLレベルの水平スケーラビリティを実現する新世代RDBMSの総称です。Google Spanner、CockroachDB、TiDBが代表的な製品です。",
      "keyPoint": "NewSQL＝SQL+ACID（RDBMSの長所）＋水平スケールアウト（NoSQLの長所）を両立",
      "relatedTopics": ["NoSQL", "CAP定理", "分散トランザクション", "Google Spanner", "CockroachDB"],
      "studyTip": "「RDBMS（整合性強・スケール弱）→NoSQL（整合性弱・スケール強）→NewSQL（整合性強・スケール強）」という進化の流れで覚えましょう。"
    },
    "tags": ["NewSQL", "分散DB", "スケーラビリティ", "ACID", "Google Spanner"]
  },
  {
    "questionId": "q-db-035",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "database",
    "topic": "結果整合性",
    "level": 10,
    "question": "結果整合性（Eventual Consistency）の説明として、正しいものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "書き込み後、即座にすべてのノードで同一のデータを読み取れることを保証する一貫性モデルである",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "それは強整合性（Strong Consistency）または線形化可能性の説明です。結果整合性は即座の一貫性を保証せず、「更新が伝播するまでの間は古いデータが読み取られる可能性がある」ことを許容する緩いモデルです。",
          "analogy": "速報値（結果整合性）は最初は古い情報かもしれませんが、時間が経てば正確な数字に更新されます。即座の正確さを保証するのは確定値（強整合性）です。"
        }
      },
      {
        "id": "b",
        "text": "更新が停止された後、時間の経過とともに最終的にすべてのレプリカが同一の値に収束することを保証する一貫性モデルである",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "結果整合性（Eventual Consistency）は「更新が行われなくなれば、十分な時間の経過後にすべてのレプリカが同一の最新値に収束する」ことを保証する一貫性モデルです。CAP定理のAP系システム（可用性と分断耐性を優先）でよく採用されます。Amazon DynamoDB、Apache Cassandraなどが採用しています。",
          "analogy": "Wi-Fiの電波が悪い場所でSNSのいいね数を見ると、まだ古い数字が表示されることがあります（一時的な不整合）。しかしネットワークが回復して時間が経てば、すべてのデバイスで同じ最新のいいね数が表示されます（最終的な収束）。これが結果整合性です。",
          "deepDive": "結果整合性の種類：①単調読み取り一貫性（一度読んだ値より古い値は読まない）②読み取り自分書き込み一貫性（自分が書いた値は必ず読める）③単調書き込み一貫性（書き込みが順序通りに適用される）④セッション一貫性（セッション内では自分の書き込みが見える）。Cassandraでは読み書きのConsistencyLevel（ONE, QUORUM, ALL等）で一貫性の強さを調整できます。"
        }
      },
      {
        "id": "c",
        "text": "結果整合性はリレーショナルデータベースでのみ実現できる一貫性モデルである",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "結果整合性はNoSQLデータベース（Cassandra、DynamoDB、CouchDB等）で一般的に採用される一貫性モデルです。強整合性を採用するリレーショナルDBMSとは対極に位置する概念です。",
          "analogy": "結果整合性は「ゆるいルール」のような概念で、厳格なリレーショナルDBよりも柔軟なNoSQLに多く採用されています。"
        }
      },
      {
        "id": "d",
        "text": "結果整合性を採用するシステムでは、データの読み取りが永久に不整合な状態になることが保証される",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "結果整合性は「最終的には整合性が取れる」ことを保証するモデルです。「永久に不整合」ではなく「一時的な不整合を許容する」のが正しい理解です。更新が止まり十分な時間が経てばすべてのレプリカは同一値に収束します。",
          "analogy": "川の水は一時的に波立つ（不整合）ことがあっても、やがて静まって平らになります（収束）。永遠に波立ち続けるわけではありません。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "結果整合性は更新伝播後に最終的に全レプリカが同一値に収束することを保証する一貫性モデルです。一時的な不整合を許容する代わりに高い可用性とスケーラビリティを実現します。",
      "keyPoint": "結果整合性＝一時的な不整合を許容するが、時間経過で全レプリカが最終的に同一値に収束",
      "relatedTopics": ["CAP定理", "BASE特性", "Cassandra", "DynamoDB", "強整合性"],
      "studyTip": "ACID（強整合性）とBASE（結果整合性）の対比を整理し、どのDBがどちらを採用しているか代表例とともに覚えましょう。"
    },
    "tags": ["結果整合性", "Eventual Consistency", "CAP定理", "NoSQL", "BASE"]
  },
  {
    "questionId": "q-db-036",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "database",
    "topic": "コンセンサスアルゴリズム",
    "level": 10,
    "question": "PaxosやRaftなどの分散コンセンサスアルゴリズムに関する説明として、正しいものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "Paxosは単一のリーダーノードがすべての決定を行い、リーダーが停止した場合はシステム全体が停止する",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "Paxosにはリーダー選出の仕組みがあり、既存のリーダーが停止した場合は新しいリーダーを選出して処理を継続できます（フォールトトレランス）。システム全体が停止するわけではありません。リーダー停止への対応こそがコンセンサスアルゴリズムの重要な機能の一つです。",
          "analogy": "合議制の組織で議長が突然倒れても、残りのメンバーで新しい議長を選んで会議を続けられます。Paxosもこれと同様です。"
        }
      },
      {
        "id": "b",
        "text": "Raftはn台のノードで(n-1)/2台までのノード障害を許容し、過半数（クォーラム）の合意でコミットを決定する",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "Raftがn台で許容できる障害ノード数は(n-1)/2台ではなく「(n-1)/2を超えない台数」つまり「n/2 - 0.5」を切り捨てた台数です。例えば5台なら2台まで（3台の過半数で合意）。(n-1)/2は5台なら2台となり合っていますが、6台では2.5台→2台が正しいため、一般的な表現として混乱しやすいです。正しくは「過半数（(n/2)+1台以上）の合意が必要」と表現します。",
          "analogy": "5人の多数決では3人以上（過半数）の同意が必要で、最大2人まで反対（または欠席）でも決議できます。"
        }
      },
      {
        "id": "c",
        "text": "Paxos・Raftはノード間で値の合意を形成するプロトコルであり、分散システムでのリーダー選出やログの複製に使用される",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "PaxosとRaftはどちらも分散システムにおけるコンセンサス（合意形成）アルゴリズムです。主な用途はリーダー選出（新リーダーの選定）、分散ログの複製（複数ノードで同一のログを保持）、設定管理（ZooKeeperはZab（Paxos系）を採用）などです。Raftは理解しやすさを重視してPaxosを改良したアルゴリズムで、CockroachDB、TiDB、etcdなどが採用しています。",
          "analogy": "バラバラの場所にいるチームメンバーが「次のチームリーダーを誰にするか」「今日の作業ログに何を記録するか」を確実に合意するための手順書（プロトコル）がPaxos/Raftです。一部のメンバーが連絡不通（障害）になっても、残りのメンバーで合意を完結させられます。",
          "deepDive": "Paxos vs Raft：①Paxos：Lamportが1989年に発表。数学的に厳密だが理解・実装が難しい。ファミリーには Multi-Paxos, Fast Paxos 等がある。②Raft：2013年に提唱。「理解しやすさ」を設計目標に掲げ、リーダー選出・ログ複製・メンバーシップ変更の3フェーズを明確に分離。Raftはリーダーが決まっている間はすべての書き込みをリーダーが受け、フォロワーへ複製します。"
        }
      },
      {
        "id": "d",
        "text": "分散コンセンサスアルゴリズムはすべてのノードが正常な場合のみ動作し、1台でも障害が発生すると停止する",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "分散コンセンサスアルゴリズムの存在意義はノード障害への耐性（フォールトトレランス）を実現することです。Paxos・Raftともに一定数のノード障害（通常は少数派のノード）があっても正常に動作し続けます。「1台でも障害で停止」するなら分散コンセンサスの意味がありません。",
          "analogy": "多数決の投票で参加者が少し欠席しても、残りの参加者で決議できます。全員が揃わないと決議できない組織は実用的ではありません。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "PaxosとRaftは分散システムでノード間の合意形成（コンセンサス）を実現するアルゴリズムです。リーダー選出・ログ複製・障害耐性に使われ、現代の分散DBの基盤技術です。",
      "keyPoint": "Paxos/Raft＝分散コンセンサスアルゴリズム。過半数の合意でコミット。ノード障害があっても過半数が生きていれば動作継続。",
      "relatedTopics": ["分散トランザクション", "ZooKeeper", "etcd", "CockroachDB", "リーダー選出"],
      "studyTip": "PaxosとRaftの違い（理解しやすさ vs 数学的厳密性）と、採用しているDBの具体例（TiDB=Raft、ZooKeeper=Zab）を覚えましょう。"
    },
    "tags": ["Paxos", "Raft", "コンセンサスアルゴリズム", "分散システム", "リーダー選出"]
  },
  {
    "questionId": "q-db-037",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "database",
    "topic": "グラフデータベース",
    "level": 10,
    "question": "グラフデータベースが最も効果的に利用できるユースケースはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "大量の時系列データを圧縮・保存し、時刻範囲で高速に検索する",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "時系列データの圧縮・保存・時刻範囲検索は時系列データベース（InfluxDB、TimescaleDB等）が最適化されているユースケースです。グラフDBの強みはノード間の関係（エッジ）を辿るクエリです。",
          "analogy": "温度センサーのログ記録（時系列）には温度計専用の帳簿（時系列DB）が最適で、人間関係の地図（グラフDB）は向いていません。"
        }
      },
      {
        "id": "b",
        "text": "SNSの友人関係を辿り、「友達の友達」を複数ホップで検索する",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "グラフデータベースはデータをノード（節点）とエッジ（辺）で表現し、ノード間の関係（グラフ構造）を辿るクエリが高速です。SNSの「友達の友達の友達…」（多ホップ関係探索）、不正検知での取引ネットワーク分析、レコメンドエンジン（協調フィルタリング）、サプライチェーン分析などが典型的な用途です。リレーショナルDBで同じことをするとJOINが増え指数関数的に遅くなります。",
          "analogy": "人間関係の「つながり」を地図で追うのがグラフDBの得意技です。「田中さんの友人の山田さんの知人の鈴木さんを通じてターゲットに繋がるか？」を素早く調べるのはリレーショナルDBより圧倒的に効率的です。LinkedInの「◯次のつながり」機能がまさにこの使い方です。",
          "deepDive": "グラフDBの代表製品：Neo4j（最も普及しているグラフDB）、Amazon Neptune、ArangoDB（マルチモデル）。グラフDB専用クエリ言語：Cypher（Neo4j）、SPARQL（RDFグラフ）。主なグラフアルゴリズム：PageRank（重要ノードの特定）、最短経路（Dijkstra）、コミュニティ検出、トライアングルカウント。知識グラフやAIのナレッジベースにも活用されています。"
        }
      },
      {
        "id": "c",
        "text": "医療画像データやビデオファイルなど大容量バイナリデータを格納・配信する",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "大容量バイナリデータ（BLOB）の格納・配信はオブジェクトストレージ（Amazon S3、Azure Blob Storage）やBLOBストアが適しています。グラフDBは関係性データ（グラフ構造）の格納・検索に特化しており、バイナリデータの格納は専門外です。",
          "analogy": "グラフDBは「人間関係マップ」の専門家であり、「物品倉庫」（バイナリデータストア）の役割とは違います。"
        }
      },
      {
        "id": "d",
        "text": "銀行口座の残高管理のような高いACIDトランザクションが必要な業務処理",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "高いACIDトランザクション要件と業務処理には伝統的なRDBMSが適しています。グラフDBもACIDをサポートするものはありますが（Neo4j等）、グラフDBの強みはACIDよりも関係性の探索にあります。銀行口座の残高管理にグラフDBを選ぶのは一般的ではありません。",
          "analogy": "カナヅチ（グラフDB）は釘を打つのが得意ですが、ネジを締めるのはドライバー（RDBMS）の方が適しています。道具は適材適所で選ぶことが重要です。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "グラフデータベースはノードとエッジで関係性を表現し、多段のつながり（多ホップ）を辿るクエリが高速です。SNS、不正検知、レコメンドエンジンなどに最適です。",
      "keyPoint": "グラフDB＝ノード（エンティティ）とエッジ（関係）で表現。関係探索（多ホップ）クエリが高速。",
      "relatedTopics": ["Neo4j", "Amazon Neptune", "知識グラフ", "PageRank", "レコメンドエンジン"],
      "studyTip": "グラフDBが適するユースケース（SNS、不正検知、ナレッジグラフ）と代表製品（Neo4j）を具体例とともに覚えましょう。"
    },
    "tags": ["グラフデータベース", "Neo4j", "ノード", "エッジ", "関係探索"]
  },
  {
    "questionId": "q-db-038",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "database",
    "topic": "時系列DB",
    "level": 10,
    "question": "時系列データベース（TSDB）の特徴として、正しいものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "時系列DBは任意の順序でデータを挿入でき、時刻情報はインデックスとしては使用されない",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "時系列DBは時刻（タイムスタンプ）を主要な軸（インデックス）として設計されており、時刻順のデータ挿入・検索を高効率で処理します。時刻情報はすべての操作の中核となります。",
          "analogy": "時計（時系列DB）は時間の流れを測ることが前提の道具です。時刻が重要でない時系列DBは概念的にあり得ません。"
        }
      },
      {
        "id": "b",
        "text": "IoTセンサーデータや株価データなど時刻付きデータの格納・圧縮・高速検索に特化し、データの自動ダウンサンプリングや保持期間管理機能を持つ",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "時系列DB（TSDB）はタイムスタンプ付きデータ（IoTセンサー、株価、サーバーメトリクス、気象データ等）の格納に特化しています。主な特徴：①時刻ベースの圧縮（デルタ圧縮等）で高圧縮率②時刻範囲検索の高速化③自動ダウンサンプリング（古いデータを粗い粒度に変換）④データ保持期間（TTL）の自動管理。代表製品：InfluxDB、TimescaleDB（PostgreSQL拡張）、Prometheus、OpenTSDB。",
          "analogy": "温度計の記録を専用の日誌（時系列DB）に残すようなイメージです。「昨日の午後3時から5時の気温変化」を素早く取り出せるよう整理されており、古いデータは「月平均」に自動圧縮（ダウンサンプリング）して保管容量を節約します。",
          "deepDive": "時系列DBの圧縮技術：①差分符号化（デルタ符号化）：連続する値の差分だけを記録 ②ゴリラ圧縮（Facebookが考案）：浮動小数点数のXOR符号化。InfluxDBのFlux言語やPrometheusのPromQLは時系列データに特化したクエリ言語です。Kubernetes監視、APM（Application Performance Monitoring）、スマートメーター分析などに広く活用されています。"
        }
      },
      {
        "id": "c",
        "text": "時系列DBではデータの更新・削除が頻繁に行われることを前提に設計されている",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "時系列DBは一般的に「追記型（Append-only）」の設計が基本です。センサーデータや株価データは過去の記録を更新・削除することなく、新しいデータを追加し続けるのが一般的なユースケースです。更新・削除が多いユースケースには通常のRDBMSが適しています。",
          "analogy": "天気の記録は過去の気温データを書き換えることはなく、毎日新しいデータを追記します。時系列DBはこの「追記のみ」の特性に最適化されています。"
        }
      },
      {
        "id": "d",
        "text": "時系列DBはテキスト検索に特化しており、全文検索クエリのパフォーマンスが優れている",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "全文検索に特化しているのはElasticsearchやOpenSearchなどの全文検索エンジンです。時系列DBは時刻範囲検索や時系列集計に特化しており、全文検索は専門外です。",
          "analogy": "温度計（時系列DB）は温度を測るのが得意で、辞書検索（全文検索エンジン）の代わりにはなりません。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "時系列DBはタイムスタンプ付きデータの格納・圧縮・時刻範囲検索に特化し、ダウンサンプリングやTTL管理も備えた専用データベースです。IoTやメトリクス監視に活用されます。",
      "keyPoint": "時系列DB＝時刻付きデータの追記型格納。時刻圧縮・時刻範囲検索・ダウンサンプリングが特徴。",
      "relatedTopics": ["InfluxDB", "Prometheus", "TimescaleDB", "IoT", "メトリクス監視"],
      "studyTip": "時系列DBが適するユースケース（IoT・監視・株価）と代表製品（InfluxDB、Prometheus）の組み合わせを覚えましょう。"
    },
    "tags": ["時系列DB", "TSDB", "InfluxDB", "Prometheus", "IoT", "ダウンサンプリング"]
  },
  {
    "questionId": "q-db-039",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "database",
    "topic": "ベクトルDB",
    "level": 10,
    "question": "ベクトルデータベース（Vector Database）の説明として、最も正しいものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "ベクトルDBは数値の配列（ベクトル）を格納し、クエリベクトルに意味的に近いベクトルを高速に検索する機能に特化したデータベースである",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "ベクトルDBはデータを高次元のベクトル（埋め込みベクトル：embedding）として格納し、ベクトル間の距離（コサイン類似度、ユークリッド距離等）を使って「意味的に近いもの」を高速に検索（近傍探索：ANN: Approximate Nearest Neighbor）する機能に特化したDBです。AIの文書検索、画像類似検索、レコメンドエンジン、RAG（Retrieval-Augmented Generation）に活用されます。",
          "analogy": "図書館で「この本と似た内容の本を探して」という要求（意味検索）に答えるために、本の内容を数値の地図（ベクトル空間）に配置し、地図上で近くにある本を素早く見つけ出す専門の図書館がベクトルDBです。キーワード一致ではなく「意味の近さ」で検索できます。",
          "deepDive": "ベクトルDBの主要技術：①埋め込みモデル（Embedding Model）：テキスト・画像を高次元ベクトルに変換（OpenAI Embeddings、BERT等）②近似最近傍探索（ANN）アルゴリズム：HNSW（Hierarchical Navigable Small World）、IVF（Inverted File Index）③代表的製品：Pinecone、Weaviate、Qdrant、Milvus、pgvector（PostgreSQL拡張）。LLMとRAGパターンを組み合わせたAIアプリケーション開発に不可欠なインフラとして急速に普及しています。"
        }
      },
      {
        "id": "b",
        "text": "ベクトルDBは線形代数の計算専用データベースであり、行列積や固有値計算をDBMS内部で実行できる",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "ベクトルDBの目的は線形代数の計算処理ではなく、高次元ベクトルの類似検索（近傍探索）です。行列積や固有値計算はNumPyやSciPyなどの数値計算ライブラリの役割であり、ベクトルDBとは別物です。",
          "analogy": "ベクトルDBは「数学の教科書（行列計算）」ではなく、「類似したものを素早く探す地図帳」です。"
        }
      },
      {
        "id": "c",
        "text": "ベクトルDBではSQLのLIKE演算子を使ってベクトルを文字列として検索する",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "ベクトルの類似検索にはLIKE演算子（文字列パターンマッチ）ではなく、コサイン類似度やユークリッド距離を用いたベクトル間の距離計算に基づく検索（近傍探索）を使います。LIKE演算子は文字列の部分一致検索であり、ベクトルの意味的類似性の検索とは全く異なります。",
          "analogy": "「この絵と似た絵を探して」という要求に、絵の名前（文字列）でLIKE検索しても意味的に似た絵は見つかりません。絵の特徴量（ベクトル）で探す必要があります。"
        }
      },
      {
        "id": "d",
        "text": "ベクトルDBは主に請求書や契約書などの業務文書のPDF格納に使用される専用データベースである",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "PDF等のバイナリ文書の格納はオブジェクトストレージ（S3等）が適しています。ベクトルDBはPDF自体の格納ではなく、PDF等の文書をAIモデルで埋め込みベクトルに変換したものを格納し、意味的な類似検索を行う用途で使われます。",
          "analogy": "ベクトルDBに格納するのはPDFファイル（原本）ではなく、PDFの内容を数値に変換した「内容の地図（ベクトル）」です。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "ベクトルDBは高次元の埋め込みベクトルを格納し、意味的な類似性に基づく近傍検索（ANN）を高速に実行する専用データベースです。LLMやAI検索に不可欠なインフラとして急速に普及しています。",
      "keyPoint": "ベクトルDB＝埋め込みベクトルを格納し、コサイン類似度等で意味的に近いデータを高速検索（ANN）",
      "relatedTopics": ["埋め込みモデル（Embedding）", "RAG", "Pinecone", "HNSW", "LLM"],
      "studyTip": "ベクトルDBの用途（LLMとの組み合わせによるRAG、画像類似検索）と代表製品（Pinecone、Weaviate、pgvector）を覚えておくと最新のAI関連問題に対応できます。"
    },
    "tags": ["ベクトルDB", "埋め込みベクトル", "ANN", "RAG", "意味検索", "LLM"]
  },
  {
    "questionId": "q-db-040",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "database",
    "topic": "データレイク",
    "level": 10,
    "question": "データレイクに関する説明として、正しいものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "データレイクはデータを格納する前にスキーマを厳密に定義（Schema on Write）しなければならない",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "データレイクの特徴は「Schema on Read（読み取り時スキーマ定義）」です。生データをそのまま格納し、読み取る際に必要なスキーマを適用します。これにより、後から分析方法を変えたり、新しいユースケースに対応したりする柔軟性があります。「Schema on Write」はデータウェアハウス（DWH）の特徴です。",
          "analogy": "DWHはレシピ（スキーマ）を先に決めてから材料を入れる厳格な料理法ですが、データレイクは材料（生データ）を先にまとめて保管しておき、料理するときにレシピを決めます。"
        }
      },
      {
        "id": "b",
        "text": "データレイクは構造化・半構造化・非構造化のすべての形式のデータを生のままスケーラブルに格納し、後から多様な分析が行えるデータ蓄積基盤である",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "データレイクは「未加工・すべてのデータを一箇所に蓄積」する考え方で、RDBのCSV、JSONのログ、画像・動画、IoTセンサーデータなどあらゆる形式のデータをそのまま格納できます。主な特徴：①大容量・低コスト（Amazon S3、Azure Data Lake等）②Schema on Read（読み取り時にスキーマ適用）③ETL前のラウデータを保持④ML・AI・BIなど多様な用途に対応。",
          "analogy": "巨大な倉庫（データレイク）に届いた荷物（データ）をそのまま保管しておき、必要なときに取り出して加工します。倉庫に入れるときは「整理しなくていい（無加工）」ですが、取り出すときに目的に合わせて仕分けします（Schema on Read）。",
          "deepDive": "データレイク vs データウェアハウス vs データレイクハウス：①データレイク：生データを安価に大量格納・Schema on Read・多目的 ②DWH：加工済み・高品質・Schema on Write・分析に最適化 ③データレイクハウス（Delta Lake, Apache Iceberg, Apache Hudi）：両者の長所を統合（生データ格納＋ACIDトランザクション＋スキーマ管理）。データガバナンス（品質・セキュリティ・系譜管理）がデータレイク運用の重要課題です。データレイクが管理されないと「データ沼（Data Swamp）」になります。"
        }
      },
      {
        "id": "c",
        "text": "データレイクはリレーショナルデータベースの一種であり、SQLのみで操作できる",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "データレイクはリレーショナルDBではなく、Amazon S3やAzure Data Lake Storageなどのオブジェクトストレージを基盤とするデータ蓄積基盤です。SQLで分析可能なツール（Athena、BigQueryなど）を組み合わせて使うことはありますが、SQLのみに限定されるわけではありません。Spark、Python、MLフレームワークなど多様な手段でアクセスします。",
          "analogy": "図書館（データレイク）には本・雑誌・DVD・新聞など様々な形式の情報が格納されており、「本の読み方（SQL）だけ」で全情報にアクセスするわけではありません。"
        }
      },
      {
        "id": "d",
        "text": "データレイクは格納容量が10TB未満の小規模なデータ処理に適している",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "データレイクはペタバイト規模以上の大量データを安価に格納・処理するために設計されています。10TBは比較的小規模であり、データレイクの真価は大規模なデータ蓄積と多様な分析にあります。",
          "analogy": "大型倉庫（データレイク）を小さなアパートの物置（小規模データ）専用に建てるようなものです。データレイクは規模の経済が活きる大量データに向いています。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "データレイクはすべての形式の生データをスケーラブルに蓄積し、後から多様な分析を行える基盤です。Schema on Read・低コスト・大容量・多目的が特徴です。",
      "keyPoint": "データレイク＝生データを無加工で大量格納（Schema on Read）。構造化・非構造化問わず格納可能。",
      "relatedTopics": ["データウェアハウス", "ETL", "データレイクハウス", "Apache Iceberg", "データガバナンス"],
      "studyTip": "データレイク・DWH・データレイクハウスの違いを「格納形式・スキーマ定義タイミング・用途」の3軸で比較する表を作って整理しましょう。"
    },
    "tags": ["データレイク", "Schema on Read", "オブジェクトストレージ", "ビッグデータ", "データ基盤"]
  }
]
