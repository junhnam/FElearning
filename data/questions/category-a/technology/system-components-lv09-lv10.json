[
  {
    "questionId": "q-sc-033",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "system-components",
    "topic": "待ち行列モデル",
    "level": 9,
    "question": "M/M/1待ち行列モデルにおいて、平均到着率λ＝8（件/秒）、平均サービス率μ＝10（件/秒）のシステムがある。このシステムの平均系内滞在時間（W）として正しいものはどれか。ただし、系内滞在時間とは待ち時間とサービス時間の合計である。",
    "choices": [
      {
        "id": "a",
        "text": "0.1秒",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "0.1秒はサービス時間（1/μ＝1/10）だけの値です。系内滞在時間Wは待ち時間も含むため、この値より大きくなります。利用率ρ＝λ/μ＝0.8を考慮する必要があります。",
          "analogy": "料理を作るだけの時間（厨房での調理時間）を答えており、注文を待つ時間（行列の待ち時間）を加え忘れた状態です。"
        }
      },
      {
        "id": "b",
        "text": "0.5秒",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "M/M/1待ち行列では、平均系内滞在時間 W＝1/(μ－λ) で求められます。W＝1/(10－8)＝1/2＝0.5秒となります。利用率ρ＝λ/μ＝8/10＝0.8であり、ρ＜1のため安定状態にあります。",
          "analogy": "銀行の窓口で、毎秒8人が来て毎秒10人を処理できる場合、少し余裕があるものの行列はでき、一人当たりの平均0.5秒待つことになります。混み具合（利用率80%）に応じて待ち時間が長くなる現象です。",
          "deepDive": "M/M/1モデルはポアソン到着・指数分布サービス・窓口1つの最も基本的な待ち行列です。主要指標：利用率ρ＝λ/μ、平均系内人数 L＝ρ/(1－ρ)、平均待ち時間 Wq＝ρ/(μ－λ)、平均系内滞在時間 W＝1/(μ－λ)。リトルの法則 L＝λW も重要で、各指標が関連付けられます。ρ→1に近づくほどW→∞となり、高負荷時のシステム設計では余裕率の確保が不可欠です。"
        }
      },
      {
        "id": "c",
        "text": "0.4秒",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "0.4秒は平均待ち時間Wq＝ρ/(μ－λ)＝0.8/2＝0.4秒であり、サービスを受けるまでの行列の待ち時間です。系内滞在時間WはWqにサービス時間1/μ＝0.1秒を加えた値で、0.4＋0.1＝0.5秒が正解です。",
          "analogy": "「行列に並ぶ時間だけ」を答えており、「実際にサービスを受けている時間」を加え忘れた状態です。レストランで席に着くまでの待ち時間は計測できたが、食事の時間を含め忘れた計算です。"
        }
      },
      {
        "id": "d",
        "text": "4秒",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "4秒は平均系内人数 L＝ρ/(1－ρ)＝0.8/0.2＝4（人）という「人数」の値です。時間と人数を混同しています。リトルの法則 L＝λW から確認するとW＝L/λ＝4/8＝0.5秒が正しい滞在時間です。",
          "analogy": "「銀行にいる平均人数（4人）」と「一人の平均滞在時間（0.5秒）」を混同してしまった状態です。人数と時間は単位が違う別の値です。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "M/M/1待ち行列の平均系内滞在時間はW＝1/(μ－λ)で求めます。λはμより小さい必要があり（ρ＜1）、差（μ－λ）が小さいほど滞在時間が長くなります。",
      "keyPoint": "系内滞在時間W＝1/(μ－λ)、待ち時間Wq＝ρ/(μ－λ)、利用率ρ＝λ/μ。WとWqの差はサービス時間1/μです。",
      "relatedTopics": ["リトルの法則", "ポアソン分布", "指数分布", "スループット", "負荷分散"],
      "studyTip": "W＝1/(μ－λ) は「捌ける余力（μ－λ）の逆数が滞在時間」と覚えましょう。余力が半分になると滞在時間は2倍になります。"
    },
    "tags": ["待ち行列", "M/M/1", "系内滞在時間", "利用率", "性能評価"]
  },
  {
    "questionId": "q-sc-034",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "system-components",
    "topic": "信頼性分析",
    "level": 9,
    "question": "マルコフモデルを用いたシステム信頼性分析に関する記述として、最も適切なものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "マルコフモデルでは、将来の状態が現在の状態だけでなく過去のすべての状態にも依存する。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "これはマルコフ性（マルコフ特性）の定義と正反対です。マルコフモデルの根本的な仮定は「未来の状態は現在の状態だけに依存し、過去の状態には依存しない（マルコフ性）」というものです。",
          "analogy": "サイコロを振って次に出る目は、今まで出た目の歴史に関係なく、常に1/6の確率です。マルコフモデルはこのような「過去を記憶しない」仕組みです。"
        }
      },
      {
        "id": "b",
        "text": "マルコフモデルでは、状態遷移率（故障率・修復率）が一定であることを仮定しており、指数分布に従う故障・修復時間に適用できる。",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "マルコフモデル（連続時間マルコフ連鎖）の前提として、状態遷移率（故障率λ・修復率μ）が定数であり、故障時間・修復時間が指数分布に従うことが必要です。この仮定のもとで定常状態確率を求め、定常アベイラビリティ A＝μ/(λ＋μ) などが導出されます。",
          "analogy": "壊れた電球の寿命を分析するとき、「今まで何時間使っていても、残りの寿命の確率分布は同じ（無記憶性）」という指数分布の性質を前提とする方法です。",
          "deepDive": "信頼性分析でのマルコフモデルの活用：2状態モデル（正常/故障）では定常アベイラビリティ A＝μ/(λ＋μ)＝MTBF/(MTBF＋MTTR)。多状態モデルでは冗長構成（例：稼働2台/故障1台/修復中など）を状態として表現し、各状態の定常確率を連立方程式で求めます。バース・デス過程（Birth-Death Process）を用いると系内人数の分布も求められます。ワイブル分布に従う故障モードには適用できない点に注意が必要です。"
        }
      },
      {
        "id": "c",
        "text": "マルコフモデルによる信頼性分析は、ハードウェア障害のみに適用でき、ソフトウェア障害の分析には使用できない。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "マルコフモデルはハードウェアに限らず、ソフトウェア信頼性成長モデル（例：NHPP型モデルとの組み合わせ）や、システム全体の障害・回復サイクルの分析にも広く使用されます。適用対象に制限はありません。",
          "analogy": "マルコフモデルは「状態と遷移」を記述する汎用的な道具です。電球の故障だけでなく、天気予報、株価予測、ソフトウェアのバグ修正サイクルにも応用できます。"
        }
      },
      {
        "id": "d",
        "text": "定常アベイラビリティは、観測期間を長くするほど値が変化し、最終的には0に収束する。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "定常アベイラビリティは観測期間が十分に長くなると一定値に収束します（定常状態）。0に収束することはなく、A＝μ/(λ＋μ) という値に落ち着きます。観測期間によらない「長期的な稼働割合」を表す指標です。",
          "analogy": "コンビニの長期的な営業率は「開いている時間の割合」で一定値になります。月日が経つほど閉店率が上がることはなく、安定した割合を保ちます。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "マルコフモデルはマルコフ性（未来は現在のみに依存）と指数分布を前提に、システムの定常アベイラビリティや状態確率を求める信頼性分析手法です。",
      "keyPoint": "定常アベイラビリティ A＝μ/(λ＋μ)＝MTBF/(MTBF＋MTTR)。マルコフ性とは「過去を忘れる性質」です。",
      "relatedTopics": ["MTBF", "MTTR", "アベイラビリティ", "指数分布", "冗長構成", "信頼性ブロック図"],
      "studyTip": "「マルコフ＝現在だけ見る」と覚えましょう。故障率λと修復率μが定数なら、A＝μ/(λ＋μ) の公式で定常稼働率を計算できます。"
    },
    "tags": ["マルコフモデル", "信頼性分析", "アベイラビリティ", "マルコフ性", "指数分布"]
  },
  {
    "questionId": "q-sc-035",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "system-components",
    "topic": "ソフトウェア定義基盤",
    "level": 9,
    "question": "ソフトウェア定義基盤（SDI: Software Defined Infrastructure）に関する記述として、最も適切なものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "SDIはハードウェアの物理的な構成をソフトウェアから変更できないようにロックし、安定性を高める技術である。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "SDIはその逆で、ハードウェアリソースをソフトウェアから柔軟に制御・変更できるようにする技術です。物理構成をロックするのではなく、仮想化と自動化によってインフラを動的に変更可能にします。",
          "analogy": "SDIはレゴブロックのように自由に組み替えられるインフラです。「固定して動かせないコンクリート建築」の説明とは正反対です。"
        }
      },
      {
        "id": "b",
        "text": "SDIはSDN（Software Defined Networking）のみを指す概念であり、ストレージや計算資源の仮想化は含まない。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "SDIはSDN（ネットワーク仮想化）だけでなく、SDS（Software Defined Storage：ストレージ仮想化）、SDDC（Software Defined Data Center：データセンター全体）など、コンピュータ・ストレージ・ネットワーク全リソースをソフトウェアで制御する包括的な概念です。",
          "analogy": "SDIは「オーケストラ全体をソフトウェアで指揮する」ことです。SDNは弦楽器（ネットワーク）だけを指揮するもので、SDIはそれを含む全楽器の指揮です。"
        }
      },
      {
        "id": "c",
        "text": "SDIはコンピュータ・ストレージ・ネットワークなどのインフラリソースをソフトウェアによって抽象化・自動化し、プログラマブルに管理する技術概念である。",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "SDI（Software Defined Infrastructure）は、従来ハードウェア固有の設定で管理していたコンピュータ（SDC）・ストレージ（SDS）・ネットワーク（SDN）を、ソフトウェアAPIを通じて抽象化・自動化・プログラマブルに制御する技術概念です。Infrastructure as Code（IaC）と組み合わせてクラウドネイティブな基盤を実現します。",
          "analogy": "従来のインフラは「専用の工具でしか変更できない機械」でした。SDIは「すべてをソフトウェアのスイッチで操作できるスマートファクトリー」のようなもので、必要な時に必要なリソースを瞬時に割り当て直せます。",
          "deepDive": "SDIの主要構成要素：1）SDN（Software Defined Networking）：OpenFlow等のプロトコルでネットワークトポロジをソフトウェア制御。2）SDS（Software Defined Storage）：物理ディスクをプールとして抽象化（例：Ceph、VMware vSAN）。3）SDC（Software Defined Compute）：ハイパーバイザによるVM管理（例：VMware、KVM）。4）SDDC（Software Defined Data Center）：上記すべてを統合管理。IaC（Terraform、Ansible等）と組み合わせることでインフラのバージョン管理・自動プロビジョニングが実現します。"
        }
      },
      {
        "id": "d",
        "text": "SDIを導入すると、物理サーバが不要になり、すべての処理がクラウド上のみで実行されるようになる。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "SDIは物理ハードウェアを不要にする技術ではなく、物理ハードウェアの上にソフトウェア層を設けて抽象化・管理しやすくする技術です。オンプレミス環境でもSDIを適用でき、物理サーバを前提とした上での柔軟な管理を実現します。",
          "analogy": "SDIは「建物の電気・空調・セキュリティをスマートBMSで一元管理する」ことです。建物（物理ハードウェア）そのものをなくす技術ではありません。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "SDIはコンピュータ・ストレージ・ネットワーク全インフラをソフトウェアAPIで抽象化・自動化する技術概念で、SDN・SDS・SDDCを包含します。クラウドネイティブ基盤の根幹をなします。",
      "keyPoint": "SDI＝ソフトウェアでインフラ全体をプログラマブルに制御。SDN（ネットワーク）＋SDS（ストレージ）＋SDC（計算）の総称です。",
      "relatedTopics": ["SDN", "SDS", "SDDC", "Infrastructure as Code", "OpenFlow", "仮想化", "クラウドネイティブ"],
      "studyTip": "「SD＋○＝ソフトウェアで○を定義」と覚えましょう。SDN＝Network、SDS＝Storage、SDDC＝Data Center。すべてを合わせたのがSDI（Infrastructure）です。"
    },
    "tags": ["SDI", "SDN", "SDS", "SDDC", "仮想化", "インフラ自動化", "IaC"]
  },
  {
    "questionId": "q-sc-036",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "system-components",
    "topic": "カオスエンジニアリング",
    "level": 9,
    "question": "カオスエンジニアリング（Chaos Engineering）に関する記述として、最も適切なものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "カオスエンジニアリングとは、ランダムな要件変更を繰り返すことでシステム開発の混乱耐性を高めるプロセス管理手法である。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "カオスエンジニアリングは開発プロセス管理手法ではありません。本番環境に意図的に障害や異常状態を注入し、システムの回復力（レジリエンス）を実験・検証するエンジニアリング手法です。",
          "analogy": "カオスエンジニアリングは「飛行機シミュレータで故意にエンジン停止を起こして操縦士の対応を訓練する」ことです。「会議で突然議題を変えて混乱させる」プロセス管理とは無関係です。"
        }
      },
      {
        "id": "b",
        "text": "カオスエンジニアリングは開発環境でのみ実施し、本番環境では絶対に行わない。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "カオスエンジニアリングの大きな特徴は、最終的に本番環境（または本番相当環境）で実施する点にあります。開発環境だけでは発見できない、本番特有のパターンや負荷に対するシステムの振る舞いを検証することが目的の一つです。もちろん段階的に進め、影響を最小化する設計が前提です。",
          "analogy": "消防訓練を「模擬建物でだけ」行っても、実際の建物の問題点（非常口の位置、煙の流れ方）は発見できません。本番相当の環境での訓練が真の脆弱性を明らかにします。"
        }
      },
      {
        "id": "c",
        "text": "カオスエンジニアリングとは、バグやセキュリティ脆弱性を意図的にコードに埋め込み、開発者の発見能力を評価するテスト技法である。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "バグを意図的にコードに埋め込むのはミューテーションテストの手法です。カオスエンジニアリングはコードではなくインフラや実行環境（ネットワーク遅延・サーバクラッシュ・依存サービス停止など）に障害を注入してシステム全体の回復力を検証します。",
          "analogy": "ミューテーションテストが「楽譜に誤音符を書いて演奏者の気付き能力を試す」ものだとすると、カオスエンジニアリングは「演奏中に楽器を壊れた状態にしてオーケストラ全体が演奏を続けられるか試す」ものです。"
        }
      },
      {
        "id": "d",
        "text": "カオスエンジニアリングは、本番環境に意図的に障害を注入してシステムの回復力（レジリエンス）を実験・検証する手法であり、Netflixが提唱したChaos Monkeyがその先駆けとして知られる。",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "カオスエンジニアリングはNetflixがクラウド移行時に開発した「Chaos Monkey」（本番環境のサーバをランダムに停止するツール）が起源です。「本番環境で障害が起きたときにシステムが正常に機能し続けるか」を、制御された実験で事前に確認する手法です。仮説（「○○が壊れてもシステムは正常に動くはず」）を立て、実験で検証するサイクルを繰り返します。",
          "analogy": "航空会社が定期的に「エンジン停止の緊急事態」シミュレーターで操縦士を訓練するのと同じ発想です。事故が起きる前に意図的に危機を作り出して対応力を鍛えます。カオスエンジニアリングは「システムの防災訓練」です。",
          "deepDive": "カオスエンジニアリングの実践ステップ：1）正常状態の指標を定義（定常状態の仮説を立てる）。2）実験グループと対照グループに分ける（カナリアリリース的アプローチ）。3）障害を注入（例：ネットワーク遅延、サーバ停止、依存サービス無効化、CPUスパイク）。4）定常状態との差異を観測・分析。5）弱点を修正してシステムを強化。主要ツール：Chaos Monkey（Netflix）、Chaos Mesh（Kubernetes向け）、Gremlin。GameDayとしてチーム全体で実施する文化も重要です。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "カオスエンジニアリングは本番環境に意図的に障害を注入してシステムのレジリエンスを検証する手法です。Netflixの「Chaos Monkey」が発端で、マイクロサービス・クラウド環境での信頼性向上に活用されます。",
      "keyPoint": "カオスエンジニアリング＝「意図的に壊して回復力を検証する」実験的手法。開発環境だけでなく本番（相当）環境での実施が重要です。",
      "relatedTopics": ["レジリエンス", "SRE（サイトリライアビリティエンジニアリング）", "マイクロサービス", "フォールトトレランス", "障害注入テスト"],
      "studyTip": "「カオス＝混乱を意図的に起こして強くなる」と覚えましょう。Chaos MonkeyがNetflixで生まれた背景（AWSへの移行で単一障害点がなくなる代わりに複雑な依存が生まれた）を理解すると本質が見えます。"
    },
    "tags": ["カオスエンジニアリング", "レジリエンス", "Chaos Monkey", "Netflix", "障害注入", "SRE"]
  },
  {
    "questionId": "q-sc-037",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "system-components",
    "topic": "大規模分散システム設計",
    "level": 10,
    "question": "大規模分散システムの設計原則であるCAP定理に関する記述として、最も適切なものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "CAP定理は、一貫性（Consistency）・可用性（Availability）・性能（Performance）の3特性について、分散システムでは同時に2つまでしか満たせないことを示している。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "CAP定理の「P」はPerformance（性能）ではなく、Partition Tolerance（分断耐性）です。ネットワーク分断が発生しても動作を継続できる特性を指します。分散システムではネットワーク分断（P）は避けられないため、実質的にCとAのトレードオフを選択することになります。",
          "analogy": "「CAP＝コンシステンシー・アベイラビリティ・パーティション耐性」は分散システムの鉄則です。Pをパフォーマンスと覚えてしまうと、全く異なる意味になります。"
        }
      },
      {
        "id": "b",
        "text": "CAP定理によれば、ネットワーク分断（Partition）が発生した場合、分散システムは一貫性（C）と可用性（A）を同時に保証することができず、どちらかを犠牲にする必要がある。",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "CAP定理（Brewer's Theorem）は、分散システムがConsistency（C：全ノードが同一データを返す）・Availability（A：全リクエストが応答を返す）・Partition Tolerance（P：ネットワーク分断時も動作継続）の3特性を同時にすべて満たすことは不可能であることを証明しています。分散システムではネットワーク分断Pは避けられないため、CとAのどちらを優先するかを設計時に決断します（CP系またはAP系）。",
          "analogy": "離島同士をつなぐ船便が嵐で止まった（ネットワーク分断）とき、島同士で同じ情報を持ち続けること（一貫性）と、各島が単独でサービスを続けること（可用性）の両立は不可能です。嵐の間は「情報が古いまま」か「サービス停止」かを選ぶしかありません。",
          "deepDive": "CAP定理に基づくデータベース分類：CP系（Consistency優先、Partition時に可用性を下げる）：HBase、ZooKeeper、MongoDB（デフォルト設定）。AP系（Availability優先、Partition時に一貫性を下げる）：Cassandra、DynamoDB、CouchDB。CA系（Partitionがない前提）：従来のRDBMS（MySQLなど）。実際の設計では「どの程度の一貫性が必要か」をPACELCモデル（Partition時のL/Cと通常時のL/Cのトレードオフ）で細かく調整することが多くなっています。"
        }
      },
      {
        "id": "c",
        "text": "CAP定理はRDBMSにのみ適用され、NoSQLデータベースには適用されない。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "CAP定理はすべての分散システム（RDBMSもNoSQLも含む）に適用される普遍的な定理です。むしろCAP定理の議論はNoSQLデータベースの設計において特に重要で、CassandraやDynamoDBなどのNoSQLシステムはAP系としてCAP定理を意識して設計されています。",
          "analogy": "重力の法則がすべての物体に適用されるように、CAP定理はあらゆる分散システムに適用される基本原理です。特定の種類のデータベースだけに適用されるわけではありません。"
        }
      },
      {
        "id": "d",
        "text": "CAP定理において、一貫性（C）・可用性（A）・分断耐性（P）の3特性はすべてトレードオフの関係にあり、どの2つの組み合わせも同時に満たすことはできない。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "CAP定理は「3つすべてを同時には満たせない」という命題であり、「2つの組み合わせが満たせない」ということではありません。CA（一貫性＋可用性：ネットワーク分断がない前提）、CP（一貫性＋分断耐性：分断時に応答を拒否）、AP（可用性＋分断耐性：分断時に古いデータを返す）の3通りの2つ取りは実現可能です。",
          "analogy": "「3枚の板のうち、3枚同時には選べないが、2枚は選べる」というのがCAP定理の正しい解釈です。「どの2枚の組み合わせも選べない」という説明は誤りです。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "CAP定理は分散システムにおいてC（一貫性）・A（可用性）・P（分断耐性）の3特性を同時に満たすことは不可能であることを示します。ネットワーク分断Pは避けられないため、実質的にCとAのトレードオフとなります。",
      "keyPoint": "分散システムでPは前提→実質CA vs AP vs CPの選択。CP＝ZooKeeper系、AP＝Cassandra系、CA＝従来のRDBMS（分断なし前提）。",
      "relatedTopics": ["NoSQL", "分散データベース", "BASE特性", "PACELC定理", "結果整合性", "分散トランザクション"],
      "studyTip": "「CAP＝一貫性・可用性・分断耐性、3つ同時は無理」と覚え、各NoSQLがCP系かAP系かを整理しましょう。試験では具体的なシステム（ZooKeeper＝CP、Cassandra＝AP）の対応も問われます。"
    },
    "tags": ["CAP定理", "分散システム", "一貫性", "可用性", "分断耐性", "NoSQL", "BASE特性"]
  },
  {
    "questionId": "q-sc-038",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "system-components",
    "topic": "冗長構成設計",
    "level": 10,
    "question": "可用性要件として年間稼働率99.99%（いわゆる「フォーナイン」）を達成したい。個々のコンポーネントの信頼性が年間稼働率99.9%の場合、冗長構成設計に関する記述として最も適切なものはどれか。ただし、故障は独立事象とする。",
    "choices": [
      {
        "id": "a",
        "text": "同一コンポーネントを2台直列に接続（シリアル冗長）することで、年間稼働率99.99%を達成できる。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "直列接続（直列システム）ではシステム全体の稼働率は各コンポーネントの稼働率の積となり、99.9%×99.9%≒99.8%となって稼働率がむしろ下がります。冗長化には並列接続（パラレル冗長）が必要です。",
          "analogy": "鎖の強さは最も弱い部分で決まるように、直列につないだコンポーネントは一つでも壊れるとシステム全体が止まります。2台直列は「より壊れやすいシステム」を作るだけです。"
        }
      },
      {
        "id": "b",
        "text": "同一コンポーネントを2台並列に接続（パラレル冗長）することで、年間稼働率99.99%を達成できる。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "2台並列のシステム停止確率は各コンポーネントの停止確率の積：0.1%×0.1%＝0.0001%となり、稼働率は100%－0.0001%＝99.9999%（シックスナイン）となります。これは99.99%の要件を超えていますが、2台並列で99.99%が達成できるという点では正しいように見えます。ただしここでの問題は、「どのような冗長構成で」「なぜそれが適切か」という観点での最も適切な記述ではありません。99.99%達成自体は正しい数字ですが、最適化（コスト最小）の観点での分析が欠けており、次の選択肢がより適切です。",
          "analogy": "目標の「フォーナイン」に対し、2台並列は「シックスナイン」という過剰品質になります。目標は達成できますが、コスト対効果の分析なしに「これが最適」とは言えません。"
        }
      },
      {
        "id": "c",
        "text": "1台のコンポーネントで99.99%の要件を満たすには、コンポーネントの年間停止時間が約52.6分以内である必要があり、99.9%のコンポーネントでは停止時間が約8.76時間となるため、単体では要件を満たせない。単体での要件達成には、コンポーネント自体の信頼性向上かアクティブ-スタンバイ構成が必要である。",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "年間99.99%稼働率での許容停止時間：8,760時間×0.01%＝0.876時間≒52.6分。一方、99.9%コンポーネントの停止時間：8,760時間×0.1%＝8.76時間。単体では要件を満たせないため、アクティブ-スタンバイ（ホットスタンバイ・コールドスタンバイ）構成かアクティブ-アクティブ冗長構成が設計上の選択肢となります。冗長化により停止確率を積で計算（0.1%×0.1%＝0.0001%→稼働率99.9999%）するため要件達成が可能です。",
          "analogy": "「年間に52分しか止まってはいけない（フォーナイン）」のに、部品一つで「年間8.76時間止まる（スリーナイン）」なら、部品を二重化（冗長化）して両方同時に壊れる確率（約0.0001%、年間約5秒）まで下げる必要があります。",
          "deepDive": "稼働率と停止時間の対応（年間）：99%（ツーナイン）≒87.6時間停止、99.9%（スリーナイン）≒8.76時間、99.99%（フォーナイン）≒52.6分、99.999%（ファイブナイン）≒5.26分、99.9999%（シックスナイン）≒31.5秒。冗長構成の選択：ホットスタンバイ（即時切替・高コスト）、ウォームスタンバイ（数分切替）、コールドスタンバイ（数十分切替・低コスト）、アクティブ-アクティブ（負荷分散も兼ねる）。RTO（Recovery Time Objective）とRPO（Recovery Point Objective）を定義してから冗長方式を選択することが重要です。"
        }
      },
      {
        "id": "d",
        "text": "コンポーネントをn台並列に接続した場合、システム稼働率はコンポーネント1台の稼働率をn倍すれば求められる。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "並列システムの稼働率はコンポーネント稼働率のn倍ではありません。正しい計算式は「システム停止確率＝各コンポーネント停止確率の積」、すなわちシステム稼働率＝1－（1－R）^n（Rはコンポーネント稼働率）です。99.9%のコンポーネント2台並列では1－0.001²＝99.9999%となり、2倍（199.8%）のような非現実的な値にはなりません。",
          "analogy": "コインを2回投げても「表が出る確率が2倍（100%超）」にはなりません。「少なくとも1回は表が出る確率」は75%で、これが並列冗長の考え方です。独立事象の確率計算では「かつ両方失敗する確率」を計算します。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "フォーナイン（99.99%）達成には年間52.6分以内の停止が条件です。99.9%のコンポーネント単体（年間8.76時間停止）では不十分で、並列冗長構成（アクティブ-スタンバイ等）が必要です。並列稼働率は1－(1－R)^nで計算します。",
      "keyPoint": "99.99%＝年間52.6分停止。並列冗長稼働率＝1－(1－R)^n。スリーナインのコンポーネント2台並列でシックスナイン(99.9999%)が実現できます。",
      "relatedTopics": ["MTBF", "MTTR", "アベイラビリティ", "ホットスタンバイ", "コールドスタンバイ", "RTO", "RPO", "アクティブ-アクティブ"],
      "studyTip": "ナイン数一覧（9が何個か）を暗記しましょう。試験では「フォーナインは年間何分の停止か」という計算問題が頻出です。8,760時間×0.01%＝52.6分の計算を素早くできるようにしてください。"
    },
    "tags": ["フォーナイン", "冗長構成", "稼働率計算", "ホットスタンバイ", "アクティブ-スタンバイ", "RTO", "RPO"]
  },
  {
    "questionId": "q-sc-039",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "system-components",
    "topic": "サーバレスアーキテクチャ",
    "level": 10,
    "question": "サーバレスアーキテクチャ（FaaS: Function as a Service）の性能特性に関する記述として、最も適切なものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "サーバレス関数はコンテナ型仮想化と同様に常時起動されており、リクエストの増減に関わらず一定のレスポンス時間を保証する。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "サーバレス関数は「常時起動」ではなく、リクエストが来たときに起動（またはコンテナが再利用）されます。しばらくリクエストがない場合はコンテナが破棄（アイドルタイムアウト）され、次のリクエスト時に新たに起動が必要となる「コールドスタート」問題が発生し、レスポンス時間が増加します。",
          "analogy": "サーバレス関数は「電気を消してから呼ばれたら電気をつける飲食店」のようなものです。常時電気がついている（常時起動）わけではなく、呼ばれるたびに電気をつける（起動する）コストがかかります。"
        }
      },
      {
        "id": "b",
        "text": "サーバレスアーキテクチャでは、コールドスタート（Cold Start）によるレイテンシの増加が発生することがあり、これはランタイムの初期化・コンテナ起動・依存ライブラリのロードに要する時間が原因である。",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "コールドスタートはサーバレス関数の代表的な性能課題で、関数インスタンスが存在しない（アイドル後または初回）状態からのリクエスト処理時に発生します。コンテナ（またはマイクロVM）の起動、ランタイム（Node.js、Python、Javaなど）の初期化、依存ライブラリのロード、アプリケーションコードの初期化（VPC設定を含む場合はさらに遅延）などが重なり、通常数十ms〜数秒のレイテンシが加わります。",
          "analogy": "毎日使うコーヒーメーカーは電源を入れてすぐ（ウォームスタート）に使えますが、長期旅行後に帰宅して初めて使う場合（コールドスタート）は、フィルタのセットや水の補充から始める必要があります。サーバレス関数の「コールドスタート」はこの「久しぶりに使う準備時間」に相当します。",
          "deepDive": "コールドスタート対策：1）Provisioned Concurrency（AWS Lambda等）：一定数のインスタンスを常時ウォーム状態で維持（コスト増加とのトレードオフ）。2）定期的なウォームアップリクエスト（ダミーリクエストで関数を生かし続ける）。3）軽量ランタイム選択（Node.js・Pythonの方がJavaよりコールドスタートが速い）。4）依存ライブラリの最小化（パッケージサイズを小さくする）。5）SnapStart（AWS Lambda Java向け）：スナップショットから復元して初期化時間を短縮。トレードオフ：サーバレスの利点（インフラ管理不要・自動スケール・実行時間課金）とコールドスタートの欠点をビジネス要件に照らして判断することが重要です。"
        }
      },
      {
        "id": "c",
        "text": "サーバレスアーキテクチャはステートフルな処理に最適化されており、関数間でメモリ上のセッション情報を自由に共有できる。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "サーバレス関数は本質的にステートレス（状態を持たない）であり、関数インスタンスが異なれば（または関数実行後にインスタンスが破棄されれば）メモリ上の情報は失われます。関数間でのセッション情報共有には、外部の状態管理サービス（Redis、DynamoDB、S3など）を利用する必要があります。",
          "analogy": "毎回替わるアルバイトの店員（サーバレス関数）に、前の客の注文内容（セッション情報）を覚えておいてもらうことはできません。情報を共有するには必ず「注文台帳（外部データベース）」に書き留める必要があります。"
        }
      },
      {
        "id": "d",
        "text": "サーバレスアーキテクチャでは、関数の実行時間に制限がなく、バッチ処理など長時間実行するジョブに最も適したアーキテクチャである。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "サーバレス関数には実行時間の上限（タイムアウト）が設定されています。例えばAWS Lambdaは最大15分、Azure Functionsは最大10分（コンサンプションプランの場合）です。長時間実行が必要なバッチ処理には、コンテナ（AWS Fargate等）や専用バッチサービスの方が適しています。",
          "analogy": "コインランドリー（サーバレス）は「1回の使用時間に制限」があります。洋服を数枚洗う短時間の処理には向いていますが、大型の布団を何時間も洗いたい場合（長時間バッチ処理）には向いていません。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "サーバレス（FaaS）の特徴的な性能課題はコールドスタートです。ランタイム・コンテナ起動・ライブラリロードの時間でレイテンシが増加します。対策としてProvisioned Concurrencyや軽量ランタイムの採用があります。",
      "keyPoint": "コールドスタート＝アイドル後の初回起動時の遅延。サーバレスはステートレスで実行時間上限あり。ウォームスタートを維持するにはProvisioned Concurrencyを使う。",
      "relatedTopics": ["FaaS", "AWS Lambda", "コンテナ", "マイクロサービス", "ステートレス", "スケールアウト", "イベント駆動アーキテクチャ"],
      "studyTip": "サーバレスの性能特性を「利点と欠点のセット」で覚えましょう。利点：自動スケール・管理不要・使った分だけ課金。欠点：コールドスタート・実行時間上限・ステートレス制約・デバッグ困難。"
    },
    "tags": ["サーバレス", "FaaS", "コールドスタート", "AWS Lambda", "ステートレス", "性能特性"]
  },
  {
    "questionId": "q-sc-040",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "system-components",
    "topic": "グリーンIT",
    "level": 10,
    "question": "データセンターのエネルギー効率を示す指標であるPUE（Power Usage Effectiveness）に関する記述として、最も適切なものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "PUEはIT機器の消費電力をデータセンター全体の消費電力で除した値であり、値が大きいほどエネルギー効率が高い。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "PUEの計算式はITとデータセンター全体の比率という観点は正しいですが、分子と分母が逆です。PUE＝データセンター全体の消費電力÷ITアウトプット（IT機器の消費電力）であり、値が1に近いほどエネルギー効率が高く、値が大きいほど効率が低くなります。",
          "analogy": "PUEは「食べた食事の総量÷体を動かすために使ったエネルギー」のような比率です。値が1に近いほど「無駄なく食事を体の動力に変換できている（高効率）」状態です。"
        }
      },
      {
        "id": "b",
        "text": "PUE＝1.0は理論上の最高効率を示し、ITアウトプット以外の電力（空調・照明・UPS損失等）が全くゼロであることを意味するが、現実には達成不可能である。実際の優れたデータセンターはPUE 1.1〜1.2程度を目指す。",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "PUE＝データセンター全体の消費電力÷IT機器の消費電力。PUE＝1.0はIT機器以外の電力消費（空調・照明・UPS・配電損失等）がゼロという理想値で現実には不可能です。2024年現在、世界トップクラスのデータセンターはPUE 1.1〜1.2（最先端は1.06程度）を実現しており、業界平均は1.5〜1.6程度です。グリーンITの観点では、自然冷却（外気冷却）の活用・高効率UPS・サーバ仮想化率向上などでPUEを下げる取り組みが重要です。",
          "analogy": "PUE 1.0は「食べたカロリーが100%体を動かすエネルギーになる」理想状態です。現実の体は消化・体熱放出などで必ずロスがあります（PUE>1.0）。優れたデータセンターはPUE 1.1で「10%だけ非IT用途に使う」高効率を実現しています。",
          "deepDive": "PUE改善の具体的手法：1）自然冷却（フリークーリング）：外気温が低い地域・季節に外気をそのまま利用（北欧データセンターが有利な理由）。2）液冷システム：水冷・油冷でCPU直接冷却（空冷より高効率）。3）高電圧直流給電（HVDC）：AC変換ロスを削減。4）サーバ仮想化：稼働率を上げてIT機器あたりの処理能力向上（分母のIT電力当たりの仕事量増加）。5）廃熱利用：サーバの廃熱を周辺建物の暖房に活用（PUEを超えたトータルエネルギー効率の議論）。WUE（Water Usage Effectiveness）やCUE（Carbon Usage Effectiveness）も合わせてデータセンターの環境性能を総合評価するトレンドです。"
        }
      },
      {
        "id": "c",
        "text": "PUEはIT機器の処理能力（FLOPS）をデータセンター全体の消費電力（kW）で除した値であり、単位はFLOPS/kWである。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "PUEは処理能力（FLOPS）を使った計算ではなく、純粋に電力の比率（消費電力÷IT機器消費電力）であり単位はありません（無次元数）。処理能力あたりのエネルギー効率（性能電力比）はPUEとは別の指標（Performance per Watt等）で評価されます。",
          "analogy": "PUEは「レストランの食材使用効率（客への料理÷仕入れた食材の総量）」という割合であり、「一人の客が食べられる料理の量（処理能力）」を測るものではありません。"
        }
      },
      {
        "id": "d",
        "text": "PUEはデータセンター全体の年間CO₂排出量を年間処理トランザクション数で除して算出し、値が小さいほどカーボン効率が高い。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "CO₂排出量をトランザクション数で除した指標はPUEではありません。PUEは電力の消費割合（消費電力÷IT電力）を示す指標です。CO₂効率を評価する指標はCUE（Carbon Usage Effectiveness）やGEC（Green Energy Coefficient）などが使われます。",
          "analogy": "PUEは「電気の使い方の効率」を測るメーターであり、「二酸化炭素をどれだけ出したか」を測るメーターではありません。それぞれ別の計器が必要です。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "PUE（Power Usage Effectiveness）はデータセンター全体消費電力÷IT機器消費電力で計算される無次元数です。PUE＝1.0が理想（現実不可能）で、1.1〜1.2が優秀なデータセンターの目標値です。",
      "keyPoint": "PUE＝DC全体消費電力÷IT機器消費電力。値が1に近いほど高効率。PUE 1.0は理論上の完全効率（現実不可能）。業界平均は約1.5〜1.6。",
      "relatedTopics": ["グリーンIT", "データセンター省エネ", "自然冷却", "WUE", "CUE", "カーボンニュートラル", "サーバ仮想化"],
      "studyTip": "「PUE＝全体÷IT、1に近いほど良い」と覚えましょう。試験では計算問題（PUEから非IT電力の割合を求める等）も出ます。PUE 1.5なら「全電力の1/3がIT以外（空調・照明等）に使われている」と解釈できます。"
    },
    "tags": ["PUE", "グリーンIT", "データセンター", "エネルギー効率", "省エネ", "カーボンニュートラル"]
  }
]
