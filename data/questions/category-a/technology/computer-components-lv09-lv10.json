[
  {
    "questionId": "q-cc-041",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "computer-components",
    "topic": "アムダールの法則",
    "level": 9,
    "question": "あるプログラムの実行時間のうち、並列化可能な部分が 80%、逐次実行のみ可能な部分が 20% である。このプログラムを 8 コアのプロセッサで実行したとき、アムダールの法則による理論上の最大高速化率（speedup）として最も近いものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "約 4.0 倍",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "アムダールの法則は Speedup = 1 / (S + (1-S)/N) で計算します。S = 0.2（逐次部分の割合）、N = 8（コア数）を代入すると、Speedup = 1 / (0.2 + 0.8/8) = 1 / (0.2 + 0.1) = 1 / 0.3 ≈ 3.33 倍となります。選択肢の中で最も近い値は約 4.0 倍です。ただし厳密には 3.33 倍であり、4.0 倍は近似として提示されています。",
          "analogy": "8人のチームで仕事をするとき、段取りや報告などの一人作業が全体の20%ある場合、いくら人数を増やしても5倍以上の速さにはなれません。8人にしても約3.3倍が限界です。",
          "deepDive": "アムダールの法則の正確な計算: Speedup = 1 / (0.2 + 0.8/8) = 1 / 0.3 = 3.33倍。この法則の重要な示唆は「逐次部分の割合が高速化の上限を決定する」ことです。逐次部分が20%あれば、コア数を∞にしても最大5倍（= 1/0.2）にしか高速化できません。これが「スケールアウトの限界」を示す基本定理です。なお、グスタフソンの法則はアムダールの法則の悲観的な視点を補完し、問題規模を増やすことで並列効率を高められることを示します。"
        }
      },
      {
        "id": "b",
        "text": "約 8.0 倍",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "8.0倍は逐次部分がゼロ（S = 0）のときの理想的な高速化率です。逐次部分が20%ある場合、8コアでも最大 1/(0.2 + 0/8) = 5倍が理論的上限であり、実際には3.33倍に留まります。",
          "analogy": "8人で分担できると思っていたが、20%の仕事は絶対に1人でやらなければならない制約がある場合、単純に8倍速くなるわけではありません。"
        }
      },
      {
        "id": "c",
        "text": "約 5.0 倍",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "5.0倍はコア数を無限大（N→∞）にしたときの理論的上限 1/S = 1/0.2 = 5倍です。コア数8の場合の実際の高速化率は 1/(0.2 + 0.1) ≈ 3.33倍となり、5倍には達しません。",
          "analogy": "コアを∞台使えれば5倍が限界ですが、8台では並列部分の高速化が不完全なため、5倍には届きません。"
        }
      },
      {
        "id": "d",
        "text": "約 1.6 倍",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "1.6倍は並列化可能部分の割合（0.8）と逐次部分（0.2）を単純に加算・比率計算した誤りです。アムダールの法則 Speedup = 1 / (S + (1-S)/N) を正しく適用すると 3.33倍になります。",
          "analogy": "「並列部分が80%だから0.8×8 + 0.2×1 = 6.6、元の処理時間1との比」のように誤った計算をした結果です。正しい公式を使いましょう。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "アムダールの法則は Speedup = 1 / (S + (1-S)/N) で表され、逐次部分の割合 S が高速化の絶対的上限 1/S を決定します。並列コア数を増やしても逐次部分がボトルネックになります。",
      "keyPoint": "逐次部分20%なら最大高速化は5倍（N→∞）。コア数8なら 1/(0.2 + 0.1) ≈ 3.33倍。コア数を増やすほど収益逓減が発生します。",
      "relatedTopics": ["グスタフソンの法則", "マルチコアプロセッサ", "並列処理の効率", "スループットとレイテンシ"],
      "studyTip": "アムダールの法則は「N→∞の上限値 = 1/S」を最初に計算し、次に実際のNを代入する手順で解くと計算ミスが減ります。"
    },
    "tags": ["アムダールの法則", "並列処理", "高速化率", "マルチコア", "スケーラビリティ"]
  },
  {
    "questionId": "q-cc-042",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "computer-components",
    "topic": "マルチコアのスケーラビリティ",
    "level": 9,
    "question": "マルチコアプロセッサにおけるスケーラビリティに関する記述として、正しいものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "コア数を2倍にすれば、すべてのアプリケーションのスループットは必ず2倍になる。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "コア数を増やしても、アプリケーションの逐次部分（並列化不可能な処理）はスケールしません。アムダールの法則により、逐次部分が存在する限りスループットの2倍改善は達成できません。また、コア間の同期・通信オーバーヘッドも増加します。",
          "analogy": "工場のラインを2倍に増やしても、最終検査が1人でしかできない作業なら、最終検査が詰まってしまい全体が2倍の速さにはなりません。"
        }
      },
      {
        "id": "b",
        "text": "メモリバンド幅が固定の場合、コア数増加に伴いメモリアクセスがボトルネックになりやすい。",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "複数のコアが同一のメモリバスやメモリコントローラを共有するため、コア数が増えるとメモリバンド幅への競合が激化します。各コアが独立してメモリアクセスを要求する場合、メモリバンド幅が固定のままではコア数に比例したスケールアップは不可能となり、メモリウォール（memory wall）問題が顕在化します。",
          "analogy": "8車線の高速道路（コア）に対して料金所（メモリコントローラ）が1つしかない場合、料金所で渋滞が発生してしまうイメージです。車線を増やしても料金所がボトルネックになります。",
          "deepDive": "メモリウォールとは、プロセッサの演算速度の伸びに対してメモリバンド幅・レイテンシの改善が追いつかない問題です。対策として、(1) キャッシュ階層の強化（L1/L2/L3キャッシュ）、(2) NUMA（Non-Uniform Memory Access）アーキテクチャ（コアに近いメモリを優先使用）、(3) HBM（High Bandwidth Memory）の採用などがあります。スケーラビリティ評価には「ルーフラインモデル」が有効で、演算強度（FLOP/Byte）からメモリバンド幅律速か演算律速かを判定できます。"
        }
      },
      {
        "id": "c",
        "text": "コア数が増えるほど、キャッシュのヒット率は必ず向上する。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "コア数増加はキャッシュの共有・競合を引き起こし、キャッシュの効果を低下させることがあります。複数コアが同じキャッシュラインを争奪する「偽共有（false sharing）」が発生すると、ヒット率が低下します。また、各コアが別々のデータセットにアクセスする場合、共有キャッシュの容量が分散されるため個々のヒット率は下がる可能性があります。",
          "analogy": "1つの本棚（共有キャッシュ）を8人で使い始めると、1人が使っていたときより1人当たりの棚のスペースが減り、必要な本が棚に入りきらなくなることがあります。"
        }
      },
      {
        "id": "d",
        "text": "ロック（mutex）を使った同期処理は、コア数が増えるほどスループットが線形に向上する。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "ロックは同時に1スレッドしかクリティカルセクションを実行できないため、コア数が増えるほどロック待ちのオーバーヘッドが増大します。ロック競合が激しい場合、コア数増加によってむしろスループットが低下することもあります（コンテンション問題）。",
          "analogy": "8人がトイレ（クリティカルセクション）の鍵を奪い合うと、5人の場合より待ち時間が長くなります。人数が増えると争いが激しくなるだけです。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "マルチコアのスケーラビリティはメモリバンド幅・同期オーバーヘッド・逐次ボトルネックの3要素に制限されます。コア数増加はすべての状況で線形な性能向上をもたらすわけではありません。",
      "keyPoint": "コア数増加 → メモリバンド幅の競合（メモリウォール）・ロック競合・偽共有 のいずれかがボトルネックになりがちです。",
      "relatedTopics": ["アムダールの法則", "メモリウォール", "NUMA", "偽共有（false sharing）", "ルーフラインモデル"],
      "studyTip": "スケーラビリティの問題では「何がボトルネックか」を問う問題が多いです。演算・メモリ・同期の3つのボトルネックを覚えておきましょう。"
    },
    "tags": ["マルチコア", "スケーラビリティ", "メモリバンド幅", "メモリウォール", "並列処理"]
  },
  {
    "questionId": "q-cc-043",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "computer-components",
    "topic": "メモリ一貫性プロトコル（MESI）",
    "level": 9,
    "question": "MESIプロトコルにおいて、あるコアのキャッシュラインが「Modified（M）」状態のとき、別のコアが同一アドレスに読み取りアクセスをした場合の動作として正しいものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "読み取りコアはキャッシュラインをInvalid（I）状態で取得し、Modifiedコアのデータは失われる。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "MESIプロトコルではデータの整合性保護が最優先です。Modifiedコアのデータ（まだメモリに書き戻されていない最新データ）を失わせることはありません。Modifiedコアが先にデータをメモリへ書き戻し、その後で読み取りコアがデータを取得します。",
          "analogy": "メモして持っている人（Modifiedコア）のノートを無断でシュレッダーにかけてから、別の人が古いホワイトボードを見るようなことはしません。まずノートの内容を先にホワイトボードに転記します。"
        }
      },
      {
        "id": "b",
        "text": "Modifiedコアがキャッシュラインをメモリに書き戻し（write-back）、両コアはShared（S）状態でそのデータを保持する。",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "MESIプロトコルでは、Modifiedコアへのスヌーピングにより読み取り要求が検知されます。Modifiedコアは最新データをメモリに書き戻し（write-back）、自身の状態をSharedに遷移します。読み取りコアはメモリから最新データを取得してShared状態で保持します。結果として両コアがShared状態で同じデータを持ちます。",
          "analogy": "Aさんが手書きで書き直したホワイトボード（Modifiedキャッシュ）を、Bさんが見たいと言ったとき、Aさんはまず変更内容を電子黒板（メモリ）に保存してから、お互いが読み取り専用で閲覧（Shared）できるようにします。",
          "deepDive": "MESIの4状態の遷移ルール: Modified（自分だけが変更版を持つ）→ read-by-other → write-back + Shared遷移。Exclusive（自分だけが保持、メモリと同一）→ 書き込みで Modified。Shared（複数コアが読み取り専用で保持）→ 書き込みで他コアをInvalidに、自分はModifiedへ。Invalid（無効）→ 読み取りでExclusive（他に保持者なし）またはShared（他に保持者あり）へ。スヌーピングバスプロトコルでは、全コアが他コアのバストランザクションを傍受して状態を更新します。"
        }
      },
      {
        "id": "c",
        "text": "読み取りコアは待機し、Modifiedコアが書き込みを完了するまで読み取りはブロックされる。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "MESIプロトコルはキャッシュコヒーレンスを維持するためにスヌーピングとwrite-backを使いますが、「Modifiedコアの書き込み完了を待つ」という動作ではありません。Modifiedコアがread要求をスヌープして自発的にwrite-backを行い、その後で読み取りコアがデータを取得します。",
          "analogy": "会議で発言者（Modifiedコア）が「言い終わるまで全員黙って待て」と言うのではなく、「読み取り要求を聞いて、すぐに議事録（メモリ）に記録してから共有する」という協調的な動作をします。"
        }
      },
      {
        "id": "d",
        "text": "Modifiedコアの状態は変わらず、読み取りコアは古いメモリのデータを取得する。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "これがキャッシュコヒーレンシ（一貫性）違反です。Modifiedコアはメモリにまだ書き戻していない最新データを持っているため、読み取りコアが古いメモリデータを取得するとデータ不整合が発生します。MESIはこれを防ぐために設計されたプロトコルです。",
          "analogy": "Aさんが銀行残高を1000円から2000円に更新したのに、Bさんが古い台帳（メモリ）を見て1000円と記録してしまう状態です。これが「不整合」であり、MESIはこれを防ぎます。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "MESIプロトコルはスヌーピングバス方式のキャッシュコヒーレンスプロトコルです。Modified状態のラインに他コアが読み取りアクセスすると、write-backが発生して両コアがShared状態になります。",
      "keyPoint": "M（Modified）へのread要求 → write-back → M→S遷移 + 読み取りコアがS状態で取得。「最新データを持つコアが責任を持ってメモリに書き戻す」のが原則です。",
      "relatedTopics": ["キャッシュコヒーレンシ", "スヌーピングプロトコル", "ディレクトリプロトコル", "MOESI", "NUMA"],
      "studyTip": "MESIの4状態（Modified・Exclusive・Shared・Invalid）の意味と遷移トリガーを表にまとめると整理しやすいです。"
    },
    "tags": ["MESIプロトコル", "キャッシュコヒーレンシ", "マルチコア", "スヌーピング", "write-back"]
  },
  {
    "questionId": "q-cc-044",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "computer-components",
    "topic": "命令レベル並列性（ILP）",
    "level": 9,
    "question": "命令レベル並列性（ILP: Instruction-Level Parallelism）を向上させる技術に関する記述として、誤っているものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "アウトオブオーダー実行は、プログラム上の命令順序とは異なる順序で命令を実行し、データ依存がない命令を先に処理することで ILP を向上させる。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "この記述は正しいです。アウトオブオーダー（OoO）実行は命令の依存関係を動的に解析し、データ依存のない命令を投機的に先実行することでパイプラインストールを削減し、ILPを向上させます。",
          "analogy": "料理の手順で「野菜を炒める（5分）→肉を焼く（10分）」の間に、「皿を用意する（依存関係なし）」という作業を前倒しするようなものです。"
        }
      },
      {
        "id": "b",
        "text": "投機実行（speculative execution）では、分岐先が確定する前に予測した分岐先の命令を実行し、予測が外れた場合は実行結果を破棄する。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "この記述は正しいです。投機実行は分岐予測と組み合わせて使われ、分岐先が確定する前に予測したパスの命令を先行実行します。予測失敗（misprediction）時はパイプラインをフラッシュして正しいパスに切り替えます。",
          "analogy": "バスの到着が確認できない間に「バスが来た」と予測してコートを着始め、来なければコートを脱ぐ（ロールバック）ようなものです。"
        }
      },
      {
        "id": "c",
        "text": "レジスタリネーミングは、WAW（Write After Write）依存やWAR（Write After Read）依存といった名前依存を除去し、真のデータ依存のみを残すことでILPを向上させる。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "この記述は正しいです。レジスタリネーミングは物理レジスタを論理レジスタに動的にマッピングし、アーキテクチャレジスタの不足から生じる偽の依存（WAW・WAR依存）を解消して、RAW（真のデータ依存）のみを残します。",
          "analogy": "会議で同じホワイトボードを奪い合うのではなく、各人に専用のホワイトボードを割り当てれば（リネーミング）、書き込みの順番待ち（WAW・WAR依存）がなくなります。"
        }
      },
      {
        "id": "d",
        "text": "スーパースカラプロセッサは、1サイクルに1命令のみを実行できるため、ILPの向上には寄与しない。",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "スーパースカラプロセッサは1サイクルに複数の命令を並行してフェッチ・デコード・実行できるプロセッサです。「1サイクル1命令」はスカラプロセッサの説明であり、スーパースカラの説明として誤りです。スーパースカラは ILP の主要な実装技術の一つです。",
          "analogy": "スーパースカラは「1つのレジ台で1人ずつ対応する（スカラ）」のではなく、「複数のレジ台で同時に複数の客を処理する（スーパースカラ）」ようなものです。1台しか使わないという説明は誤りです。",
          "deepDive": "スーパースカラプロセッサは複数の実行ユニット（ALU・FPU・ロードストアユニット等）を持ち、1クロックサイクルで複数命令を発行（issue）します。ILP向上の主な技術: (1)スーパースカラ（複数命令の同時発行）、(2)パイプライン（命令の段階的並列実行）、(3)アウトオブオーダー実行、(4)投機実行・分岐予測、(5)レジスタリネーミング。これらはすべてILP向上に寄与します。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "ILPを向上させる技術には、スーパースカラ・アウトオブオーダー実行・投機実行・レジスタリネーミング・パイプラインがあります。スーパースカラは「複数命令の同時実行」であり、ILP向上の中核技術です。",
      "keyPoint": "WAR・WAW依存は「名前依存（偽依存）」であり、レジスタリネーミングで除去できます。RAW依存は「真のデータ依存」で除去できません。",
      "relatedTopics": ["パイプライン処理", "スーパースカラ", "VLIW", "分岐予測", "アウトオブオーダー実行"],
      "studyTip": "ILPの技術は「問題を見つけて解決する」という構造で整理しましょう。ハザード（データ・制御・構造）とその解決策をセットで覚えると効果的です。"
    },
    "tags": ["ILP", "命令レベル並列性", "スーパースカラ", "アウトオブオーダー", "レジスタリネーミング"]
  },
  {
    "questionId": "q-cc-045",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "computer-components",
    "topic": "電力効率とクロックゲーティング",
    "level": 9,
    "question": "CMOSロジック回路における動的電力消費の主要な低減技術として、クロックゲーティング（clock gating）の説明として正しいものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "クロックゲーティングは、未使用の回路ブロックへのクロック信号の供給を停止し、フリップフロップの無駄な切り替えによる電力消費を削減する技術である。",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "CMOSの動的電力消費は P = α × C × V² × f （α: スイッチング活性、C: 容量、V: 電圧、f: 周波数）で表されます。クロックゲーティングはスイッチング活性 α を低減する技術で、処理に関与しない回路ブロックへのクロック供給を論理ゲート（AND/OR等）で遮断し、フリップフロップの無駄な状態切り替えを防止します。",
          "analogy": "オフィスで誰もいない部屋の電灯を消す（スイッチで遮断する）ように、使っていない回路ブロックのクロックを「ゲート（門）」で止めて電力を節約します。",
          "deepDive": "クロックゲーティングはSoC設計で最も広く使われる低消費電力技術の一つです。実装レベルでは「ゲーティングセル（クロックゲートセル）」が使われ、クロックエネーブル（enable）信号がローのとき下流のクロックを遮断します。注意点として、クロックゲーティングの制御ロジック自体が電力を消費すること、グリッチ（不要なパルス）を防ぐために制御信号の生成タイミングが重要なこと、テスト・検証が複雑になることが挙げられます。現代のSoCでは数万個のクロックゲートセルを持つ設計が一般的です。"
        }
      },
      {
        "id": "b",
        "text": "クロックゲーティングは、クロック周波数を動的に下げる技術であり、リアルタイムOSとの組み合わせでのみ効果を発揮する。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "クロック周波数を動的に変更するのは「ダイナミック周波数スケーリング（DVS/DVFS）」の技術です。クロックゲーティングは周波数を変えるのではなく、特定ブロックへのクロック信号の供給自体を停止する技術です。RTOSとの連携も必須ではありません。",
          "analogy": "「時計の針の速度を遅くする（周波数スケーリング）」と「時計を止める（クロックゲーティング）」は別の操作です。クロックゲーティングは完全に停止します。"
        }
      },
      {
        "id": "c",
        "text": "クロックゲーティングは、電源電圧を下げることで漏れ電流（リーク電流）を削減する技術である。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "電源電圧を下げてリーク電流を削減するのはパワーゲーティングや電圧スケーリング（DVS）の説明です。クロックゲーティングはクロック信号を遮断することで「動的電力（スイッチング電力）」を削減する技術です。リーク電流は静的電力であり、クロックゲーティングでは削減できません。",
          "analogy": "水道管の水圧を下げる（電圧スケーリング）のではなく、蛇口を閉める（クロックゲーティング）というイメージです。蛇口を閉めても水圧（電圧）は変わりません。"
        }
      },
      {
        "id": "d",
        "text": "クロックゲーティングは、プロセッサを完全に停止してバッテリー寿命を延ばすスリープ状態への移行技術である。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "プロセッサを完全に停止してスリープ状態に移行するのは「パワーゲーティング」や「アイドルステート管理（C-state）」の技術です。クロックゲーティングは特定の回路ブロックへのクロックを選択的に止める技術で、プロセッサ全体を停止させるものではありません。",
          "analogy": "工場全体を閉める（スリープ/パワーゲーティング）のではなく、使っていない特定のラインだけを一時停止（クロックゲーティング）するイメージです。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "CMOSの電力消費は動的電力（スイッチング）と静的電力（リーク）に分かれます。クロックゲーティングは動的電力を削減するために未使用ブロックへのクロック供給を遮断する技術です。",
      "keyPoint": "動的電力 = α×C×V²×f。クロックゲーティングは α（スイッチング活性）を削減します。リーク電流（静的電力）の削減にはパワーゲーティングが有効です。",
      "relatedTopics": ["DVFS（動的電圧周波数スケーリング）", "パワーゲーティング", "CMOSトランジスタ", "低消費電力設計", "SoC"],
      "studyTip": "電力削減技術を「動的電力を減らす（クロックゲーティング・DVS）」と「静的電力を減らす（パワーゲーティング）」に分類して覚えると整理しやすいです。"
    },
    "tags": ["クロックゲーティング", "電力効率", "CMOS", "動的電力", "低消費電力設計"]
  },
  {
    "questionId": "q-cc-046",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "computer-components",
    "topic": "キャッシュコヒーレンシの詳細設計",
    "level": 10,
    "question": "大規模マルチプロセッサシステムにおいて、スヌーピングプロトコルの代わりにディレクトリプロトコルが採用される主な理由として最も適切なものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "ディレクトリプロトコルはスヌーピングより実装が単純であり、小規模システムでも性能が高い。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "ディレクトリプロトコルはスヌーピングより実装が複雑です。各キャッシュラインに対して保持者情報を管理するディレクトリを必要とし、その分のメモリオーバーヘッドと管理ロジックが加わります。小規模システムではスヌーピングの方がシンプルで低レイテンシです。",
          "analogy": "図書館の本の貸し出し管理（ディレクトリ）は、全員が全員の本棚を覗きながら確認する（スヌーピング）より管理は複雑ですが、大人数になったときに無駄な通知が減ります。"
        }
      },
      {
        "id": "b",
        "text": "スヌーピングプロトコルでは、全プロセッサへのブロードキャストが必要なため、プロセッサ数増加に伴いバストラフィックが爆発的に増大する。",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "スヌーピングプロトコルは共有バスを使い、すべてのキャッシュアクセスをブロードキャストします。プロセッサ数が N のとき、バストラフィックは O(N) のオーダーで増大します。大規模システム（64コア以上など）ではバス帯域幅が枯渇してスケールしなくなります。ディレクトリプロトコルは共有バスの代わりにディレクトリを使い、必要なプロセッサにのみポイントツーポイントで通知するため、スケーラビリティが高いです。",
          "analogy": "全社員に一斉メール（スヌーピング/ブロードキャスト）では社員が増えるほどメールが埋もれます。関係者だけに個別通知（ディレクトリ/ポイントツーポイント）の方が大組織では効率的です。",
          "deepDive": "スヌーピング vs ディレクトリの比較: スヌーピングはレイテンシが低く（バス1ホップ）実装がシンプルですが、共有バスのバンド幅がボトルネックとなりスケールしません（~32コアが実用上限の目安）。ディレクトリは各キャッシュラインの保持状態（存在するコア集合）をメモリ側のディレクトリで管理し、Invalidation/Update通知を必要なコアにのみ送信します。大規模NUMAシステム（64コア以上）で採用されます。オーバーヘッドとして、メモリ容量の数%がディレクトリに消費されます。"
        }
      },
      {
        "id": "c",
        "text": "ディレクトリプロトコルはキャッシュミスのレイテンシがスヌーピングより常に低い。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "ディレクトリプロトコルはキャッシュミス時にディレクトリへの問い合わせという追加ホップが発生するため、レイテンシはスヌーピング（共有バスへの直接ブロードキャスト）より高くなります。スヌーピングの利点はまさにこの低レイテンシです。",
          "analogy": "「全員に同時に聞く（スヌーピング）」より「担当者に聞いてから関係者に通知してもらう（ディレクトリ）」の方が、少人数では速くても、実際は往復の手間があり必ずしも速くはありません。"
        }
      },
      {
        "id": "d",
        "text": "ディレクトリプロトコルは、キャッシュコヒーレンスを完全に保証することができないため、ソフトウェアによる補完が必要である。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "ディレクトリプロトコルはハードウェアレベルでキャッシュコヒーレンスを完全に保証します。「ソフトウェアによる補完が必要」というのは誤りです。むしろ、ハードウェアコヒーレンスを持たない一部のGPUやDSPではソフトウェアでの明示的なキャッシュ管理が必要ですが、それはディレクトリプロトコルとは別の話です。",
          "analogy": "銀行のオンラインシステムが残高を自動的に整合させる（ハードウェアコヒーレンス）のに、なぜか手動で帳簿を付けなければならないと言っているようなものです。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "スヌーピングはブロードキャスト型で小規模向け（低レイテンシだがスケールしない）、ディレクトリはポイントツーポイント型で大規模向け（高レイテンシだがスケーラブル）です。",
      "keyPoint": "スヌーピング: 共有バス + ブロードキャスト → O(N) トラフィック増大 → 大規模非対応。ディレクトリ: ポイントツーポイント通知 → スケーラブル → NUMAに採用。",
      "relatedTopics": ["MESIプロトコル", "NUMAアーキテクチャ", "マルチプロセッサ", "スケーラビリティ", "インターコネクト"],
      "studyTip": "「なぜスヌーピングはスケールしないのか」＝ブロードキャストによるバス帯域幅の枯渇、という因果関係を覚えておくと応用問題にも対応できます。"
    },
    "tags": ["キャッシュコヒーレンシ", "ディレクトリプロトコル", "スヌーピング", "スケーラビリティ", "マルチプロセッサ"]
  },
  {
    "questionId": "q-cc-047",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "computer-components",
    "topic": "VLIWアーキテクチャ",
    "level": 10,
    "question": "VLIW（Very Long Instruction Word）アーキテクチャの特徴として、正しいものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "VLIWは実行時に命令の依存関係をハードウェアが動的にスケジューリングするため、コンパイラの役割は軽微である。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "VLIWはコンパイラが静的に命令スケジューリングを行い、依存関係のない命令を1つの長命令語（VLIW）にまとめます。実行時のハードウェアによる動的スケジューリングはVLIWの特徴ではなく、むしろアウトオブオーダー実行プロセッサ（スーパースカラ）の特徴です。VLIWではコンパイラの最適化能力が性能を大きく左右します。",
          "analogy": "VLIWは「シェフ（コンパイラ）が事前に調理手順を最適化して調理師（実行ユニット）に指示書を渡す」方式です。コンパイラがすべての段取りをします。"
        }
      },
      {
        "id": "b",
        "text": "VLIWは1つの長命令語に複数の操作を埋め込み、コンパイラが静的スケジューリングで並列実行を実現する。",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "VLIWは1命令語の中に複数の演算フィールド（ALU演算・ロード・ストア・分岐等）を持ち、各フィールドが対応する実行ユニットに同時に発行されます。コンパイラがコンパイル時に命令間の依存関係を解析し、並列に実行できる操作を同一命令語にパックします。ハードウェアはコンパイラの指示通りに実行するだけで済むため、制御ロジックがシンプルになります。",
          "analogy": "「午前10時に全員が一斉に各自の担当作業を開始する」という仕事の割り当て表（VLIW命令語）を、事前に人事部（コンパイラ）が作成して配布する方式です。現場（ハードウェア）は割り当て表通りに動くだけです。",
          "deepDive": "VLIWの歴史と応用: 1980年代にJosh Fisherが提案し、DSP（Analog DevicesのTigerSHARC等）や組み込みプロセッサで広く採用されています。Intel ItaniumはVLIWの変種であるEPIC（Explicitly Parallel Instruction Computing）を採用しました。VLIWの課題: (1) バイナリ互換性の問題（実行ユニット数が変わるとバイナリを再コンパイル必要）、(2) コード密度の低下（NOP命令で埋めなければならないスロット）、(3) 分岐予測ミス時の性能低下、(4) キャッシュミス等の実行時レイテンシをコンパイル時に予測困難な問題があります。"
        }
      },
      {
        "id": "c",
        "text": "VLIWプロセッサはキャッシュミスなどのランタイムイベントに対してスーパースカラより柔軟に対応できる。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "VLIWはコンパイル時の静的スケジューリングに依存するため、キャッシュミスなどの実行時（ランタイム）イベントへの対応が苦手です。スーパースカラはアウトオブオーダー実行などの動的スケジューリングでランタイムイベントに柔軟に対応できます。VLIWはキャッシュミス発生時に多数のNOPスロットが発生して性能が低下します。",
          "analogy": "事前に書いたスケジュール表（VLIW）は突発的なトラブル（キャッシュミス）が起きると計画が崩れます。一方、ベテランマネージャー（スーパースカラ）はその場で臨機応変に対応できます。"
        }
      },
      {
        "id": "d",
        "text": "VLIWはスーパースカラと比べてハードウェアが複雑であり、消費電力が大きい。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "VLIWはスーパースカラのような動的スケジューリングロジック（OoOエンジン・ROB・命令ウィンドウ等）が不要なため、ハードウェアはシンプルで消費電力が小さい傾向があります。これはVLIWが組み込みシステムやDSPで採用される主な理由の一つです。複雑なのはVLIWを最適化するコンパイラ側です。",
          "analogy": "工場の機械（ハードウェア）をシンプルにして、複雑な段取り（スケジューリング）を事前に設計部門（コンパイラ）が請け負うことで、現場の設備投資（回路面積・電力）を抑えられます。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "VLIWは1命令語に複数の操作を静的にパックし、コンパイラが並列スケジューリングを担当します。ハードウェアはシンプルになりますが、ランタイムイベントへの柔軟性が低く、コンパイラ品質が性能を決定します。",
      "keyPoint": "VLIW = コンパイラが静的スケジューリング。スーパースカラ = ハードウェアが動的スケジューリング。前者はシンプルで低電力、後者は柔軟だが複雑。",
      "relatedTopics": ["スーパースカラ", "アウトオブオーダー実行", "EPIC（Itanium）", "DSP", "ILP"],
      "studyTip": "VLIWとスーパースカラは「誰がスケジューリングを担当するか」（コンパイラ vs ハードウェア）という軸で対比して覚えると混乱しません。"
    },
    "tags": ["VLIW", "アーキテクチャ", "静的スケジューリング", "コンパイラ最適化", "ILP"]
  },
  {
    "questionId": "q-cc-048",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "computer-components",
    "topic": "メモリバンド幅のボトルネック分析",
    "level": 10,
    "question": "あるプロセッサの演算性能が 100 GFLOPS（毎秒100億浮動小数点演算）、メモリバンド幅が 50 GB/s、各演算で使用するデータが 4 バイト（32ビット単精度）の場合、このシステムにおけるルーフラインモデルに基づく最大実効性能を制限する要因として正しいものはどれか。ただし、対象アルゴリズムの演算強度は 1 FLOP/Byte とする。",
    "choices": [
      {
        "id": "a",
        "text": "演算性能（100 GFLOPS）が律速となり、最大性能は 100 GFLOPS に制限される。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "演算強度が 1 FLOP/Byte のとき、メモリバンド幅 50 GB/s が供給できる演算量は 50 GB/s × 1 FLOP/Byte = 50 GFLOPS です。演算性能上限の100 GFLOPSに達する前に、メモリバンド幅によって50 GFLOPSに制限されます。したがって演算性能は律速ではありません。",
          "analogy": "工場の生産能力（演算性能）が1日100個でも、材料の搬入（メモリバンド幅）が1日50個分しか来ない場合、50個しか生産できません。材料不足が律速です。"
        }
      },
      {
        "id": "b",
        "text": "メモリバンド幅（50 GB/s）が律速となり、最大実効性能は 50 GFLOPS に制限される。",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "ルーフラインモデルでは実効性能 = min(演算ピーク性能, メモリバンド幅 × 演算強度) で求めます。演算強度 = 1 FLOP/Byte のとき、メモリバンド幅律速の上限は 50 GB/s × 1 FLOP/Byte = 50 GFLOPS です。演算ピーク性能の100 GFLOPSより低いため、メモリバンド幅がボトルネックとなり最大実効性能は 50 GFLOPS に制限されます。",
          "analogy": "高速な料理人（100皿/分）でも、食材の配送（50皿分/分）が追いつかなければ、最大で50皿/分しか作れません。配送がボトルネックです。",
          "deepDive": "ルーフラインモデルの詳細: 実効性能 = min(Ppeak, B×I) where Ppeak = ピーク演算性能、B = メモリバンド幅、I = 演算強度（FLOP/Byte）。演算強度が低い（I < Ppeak/B = 100/50 = 2）アルゴリズムはメモリバンド幅律速（memory-bound）、高い（I > 2）アルゴリズムは演算律速（compute-bound）です。この問題のI = 1 < 2 なのでmemory-bound。最適化の方向性: memory-bound → データ再利用・タイリング・データ圧縮、compute-bound → ベクトル化・FMA命令の利用。"
        }
      },
      {
        "id": "c",
        "text": "演算強度が 1 FLOP/Byte であるため、演算性能とメモリバンド幅は同時に律速し、最大性能は 75 GFLOPS となる。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "ルーフラインモデルでは演算性能とメモリバンド幅の「低い方」が律速となり、平均を取るわけではありません。両者が同時に律速することもなく、min(100, 50×1) = min(100, 50) = 50 GFLOPS が正しい上限です。75 GFLOPS は (100+50)/2 という誤った平均計算の結果です。",
          "analogy": "道路の速度制限が50 km/hと100 km/hの2か所ある場合、実際の速度は制限が厳しい方の50 km/hに従います。2つの平均の75 km/hで走ることはできません。"
        }
      },
      {
        "id": "d",
        "text": "演算強度が 1 FLOP/Byte であるため、データ型サイズの 4 バイトを考慮すると最大性能は 12.5 GFLOPS となる。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "演算強度はすでに FLOP/Byte の単位で与えられており、データ型サイズは演算強度の計算にすでに組み込まれています。「1 FLOP/Byte × 4 Byte/演算 = 4 FLOP/演算」のように再度データ型サイズを掛けることは二重計算になります。正しくは メモリバンド幅 × 演算強度 = 50 GB/s × 1 FLOP/Byte = 50 GFLOPS です。",
          "analogy": "時速50 kmで走ると言っているのに、さらに「車のタイヤは4本」という情報を掛けてしまうような計算の二重適用です。演算強度はすでに単位変換済みです。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "ルーフラインモデルでは実効性能 = min(演算ピーク, バンド幅×演算強度) で求めます。演算強度が低いアルゴリズム（memory-bound）はメモリバンド幅がボトルネックになります。",
      "keyPoint": "境界演算強度 = Ppeak / B = 100/50 = 2 FLOP/Byte。I < 2 → memory-bound（バンド幅律速）。I > 2 → compute-bound（演算律速）。この問題はI = 1 < 2 なのでmemory-bound。",
      "relatedTopics": ["ルーフラインモデル", "メモリウォール", "FLOPS", "キャッシュ最適化", "HBM"],
      "studyTip": "ルーフラインモデルは「横軸: 演算強度（FLOP/Byte）、縦軸: 実効性能（GFLOPS）」のグラフで理解すると視覚的に把握しやすいです。"
    },
    "tags": ["メモリバンド幅", "ルーフラインモデル", "演算強度", "ボトルネック分析", "GFLOPS"]
  },
  {
    "questionId": "q-cc-049",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "computer-components",
    "topic": "システムオンチップ（SoC）設計",
    "level": 10,
    "question": "スマートフォン向けSoC（System on Chip）の設計に関する記述として、適切でないものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "big.LITTLEアーキテクチャは、高性能コアと低電力コアを組み合わせることで、処理負荷に応じてコアを切り替え、性能と電力効率を両立する。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "この記述は正しいです。ARM big.LITTLEはヘテロジニアスマルチプロセッシング（HMP）の代表例で、高性能なCorteX-A72等の「bigコア」と省電力なCortex-A53等の「LITTLEコア」を同一チップに集積し、負荷に応じて切り替えてバッテリー寿命と性能を最適化します。",
          "analogy": "スポーツカー（bigコア）と軽自動車（LITTLEコア）を両方持ち、高速道路では前者を、市街地では後者を使い分けることでガソリン（電力）を節約します。"
        }
      },
      {
        "id": "b",
        "text": "SoCは一般に、CPU・GPU・NPU・DSP・モデム・センサーハブなどの複数の機能ブロック（IP）を1チップに統合することで、消費電力と通信レイテンシを削減する。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "この記述は正しいです。SoCの主なメリットは、複数チップ間の通信をオンチップバスに置き換えることで、チップ間通信のレイテンシと消費電力を削減できることです。Appleのシリコン、Qualcomm Snapdragon、MediaTek Dimensityなどが代表例です。",
          "analogy": "バラバラの部品（CPU・GPU・モデム）をそれぞれ別の建物に置くのではなく、1つのビル（SoC）にまとめることで、部門間の移動時間（通信レイテンシ）と移動コスト（消費電力）を削減します。"
        }
      },
      {
        "id": "c",
        "text": "SoCの製造プロセスの微細化（nm）が進むと、トランジスタ当たりの消費電力は増加し、リーク電流の問題が深刻になる。",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "微細化が進むとトランジスタ1個当たりの消費電力は「スイッチング電力」として削減される傾向がありますが、リーク電流（静的電力）の問題は深刻化します。しかし「消費電力は増加する」という表現は誤りです。微細化の主要メリットの一つはトランジスタ当たりの電力削減であり、「増加する」は適切ではありません。ただしリーク電流の増加は事実で、これがSoC微細化の主要課題の一つです。この記述は「消費電力は増加し」の部分が誤りであり、「適切でないもの」として正解となります。",
          "analogy": "部品を小さくすれば（微細化）使う電気は減りますが、小さくなるほど壁の隙間から電気が漏れやすくなる（リーク電流）という問題があります。「電力が増える」という記述は誤りです。",
          "deepDive": "半導体の微細化と電力の関係: スケーリング則（デナード則）では電圧・電流・寸法を同比率で縮小すると電力密度は一定に保たれるとされましたが、22nm以下ではデナード則が崩壊しています。現在はゲート絶縁膜の薄膜化によるリーク電流増大（サブスレッショルドリーク、ゲートトンネル電流）が問題です。対策としてHigh-k Metal Gate（HKMG）、FinFET（立体トランジスタ）、GAA（Gate All Around）トランジスタが採用されています。3nmプロセスのSoCではパワーゲーティングとFin構造の最適化でリーク対策が行われています。"
        }
      },
      {
        "id": "d",
        "text": "SoCに統合されたNPU（Neural Processing Unit）は、行列演算や畳み込み演算に特化したアクセラレータであり、汎用CPUより大幅に高い電力効率でAI推論を実行できる。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "この記述は正しいです。NPUはディープラーニングの主要演算（行列乗算・ReLU等の活性化関数）をハードウェアで直接実行する専用アクセラレータです。汎用CPUより電力効率（TOPS/W: Tera Operations per Second per Watt）が何桁も高く、スマートフォンでのオンデバイスAI推論に不可欠です。",
          "analogy": "電卓（NPU）は暗算（CPU）より四則演算を圧倒的に速く・少ない労力でこなせるように、NPUはAI演算に特化した「専用計算機」です。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "SoCの微細化ではスイッチング電力の削減が主目的ですが、リーク電流の増大が課題です。「トランジスタ当たりの消費電力が増加する」という記述は微細化の効果として誤りです。",
      "keyPoint": "微細化 → スイッチング電力削減（メリット）＆ リーク電流増大（課題）。「増加する」は誤り。デナード則の崩壊により現代SoCでは電力管理が最重要設計課題の一つです。",
      "relatedTopics": ["big.LITTLE", "FinFET", "デナード則", "NPU", "低消費電力設計", "DVFS"],
      "studyTip": "SoC設計の問題では「微細化のメリット（集積度向上・スイッチング電力削減）とデメリット（リーク電流・製造コスト増）」を両面から理解しておく必要があります。"
    },
    "tags": ["SoC", "システムオンチップ", "微細化", "リーク電流", "big.LITTLE", "NPU"]
  },
  {
    "questionId": "q-cc-050",
    "examType": "科目A",
    "category": "テクノロジ系",
    "subcategory": "computer-components",
    "topic": "量子コンピュータの基礎原理",
    "level": 10,
    "question": "量子コンピュータの基礎概念に関する記述として、正しいものはどれか。",
    "choices": [
      {
        "id": "a",
        "text": "量子ビット（qubit）は常に0または1の確定した値を持ち、古典的ビットと同じように扱うことができる。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "qubitの最大の特性は「重ね合わせ（superposition）」であり、測定されるまでは0と1の両方の状態が確率的に共存します。測定した瞬間に確定した0または1のどちらかに「波動関数の収縮」が起き、その後は確定した値になります。「常に確定した値を持つ」という記述は誤りです。",
          "analogy": "コインを空中に投げているとき（重ね合わせ状態）は表でも裏でもある可能性があります。手でキャッチして見た瞬間（測定）に初めて表か裏かが確定します。古典ビットはコインを最初から固定している状態です。"
        }
      },
      {
        "id": "b",
        "text": "量子もつれ（entanglement）により、距離によらず瞬時に情報を伝送できるため、光速を超えた通信が可能になる。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "量子もつれは2つのqubitの状態が相関していることを意味しますが、これを利用した情報の瞬時伝送（光速を超えた通信）は不可能です。測定結果はランダムであり、もつれた相手の測定結果を事前に制御することはできません。量子もつれは「量子テレポーテーション」や量子暗号鍵配送（QKD）に使われますが、情報速度は古典チャネル（光速以下）に依存します。",
          "analogy": "双子が同じ服を着るという「もつれ」があっても、片方が服を着替えた（測定）という情報は電話（古典チャネル）で教えなければ伝わりません。見た目が相関していても、その情報を送る手段が必要です。"
        }
      },
      {
        "id": "c",
        "text": "量子重ね合わせと干渉を利用することで、特定の問題（素因数分解・検索等）において古典コンピュータより指数的または多項式的に高速なアルゴリズムを実現できる場合がある。",
        "isCorrect": true,
        "explanation": {
          "whyCorrect": "量子コンピュータが優位性を持つ代表例: (1) Shorのアルゴリズムによる素因数分解（古典の指数時間 → 量子の多項式時間）、(2) Groverのアルゴリズムによる非構造化データベース検索（古典のO(N) → 量子のO(√N)）。これらは重ね合わせで多数の可能性を同時探索し、干渉（interference）で正解の確率振幅を強め、誤答の確率振幅を打ち消すことで効率化します。ただし「すべての問題で速い」わけではなく、特定の問題構造に依存します。",
          "analogy": "迷路を解くとき、古典コンピュータは1つのルートずつ試しますが、量子コンピュータは重ね合わせで全ルートを同時に試し、干渉によって行き止まりのルート（誤答）を打ち消して正解のルートだけを際立たせます。",
          "deepDive": "量子アルゴリズムの優位性の詳細: Shorのアルゴリズムは現在のRSA暗号（大きな数の素因数分解が困難なことに依拠）を理論上破ることができ、量子コンピュータの実用化が暗号技術に与える影響は甚大です（Post-Quantum Cryptography: PQCが研究されています）。Groverのアルゴリズムは二乗根の高速化（指数的ではなく多項式的速度向上）を提供します。現在の課題: qubitの「デコヒーレンス（外部ノイズによる量子状態の崩壊）」が大規模量子計算の実現を妨げており、量子誤り訂正（QEC）が重要研究課題です。"
        }
      },
      {
        "id": "d",
        "text": "量子コンピュータは古典コンピュータの完全な代替となり、すべての計算処理を古典コンピュータより高速に処理できる。",
        "isCorrect": false,
        "explanation": {
          "whyWrong": "量子コンピュータが優位性を持つのは特定のアルゴリズム（素因数分解・最適化・量子シミュレーション等）に限られます。一般的なワープロ・表計算・動画再生・ゲームなどの処理では量子コンピュータは古典コンピュータより遅いか、または不適切です。量子コンピュータは汎用コンピュータではなく、特定問題専用の加速器として位置付けられています。また現時点では雑音の多い中規模量子（NISQ）デバイスの段階にあります。",
          "analogy": "超高性能なスーパーコンピュータでも「ゲームのコントローラー入力の処理」は普通のパソコンの方が適しているように、最高性能が「すべての処理で最速」を意味するわけではありません。適材適所が重要です。"
        }
      }
    ],
    "overallExplanation": {
      "summary": "量子コンピュータは重ね合わせ・もつれ・干渉を利用して特定の問題（素因数分解・検索等）で古典より高速なアルゴリズムを実現しますが、汎用代替品ではありません。",
      "keyPoint": "Shorのアルゴリズム（素因数分解: 指数→多項式）、Groverのアルゴリズム（検索: O(N)→O(√N)）が代表的な量子優位性の例。もつれでも光速超通信は不可能。",
      "relatedTopics": ["Shorのアルゴリズム", "Groverのアルゴリズム", "量子誤り訂正", "Post-Quantum Cryptography", "デコヒーレンス"],
      "studyTip": "量子コンピュータの問題では「できること（特定問題での高速化）」と「できないこと（光速超通信・全問題での高速化）」を混同しないことが重要です。"
    },
    "tags": ["量子コンピュータ", "qubit", "重ね合わせ", "量子もつれ", "Shorのアルゴリズム", "Groverのアルゴリズム"]
  }
]
